#+STARTUP: align
#+OPTIONS: toc:1
#+PAGEID: 1774869651
#+VERSION: 87
#+TITLE: ACD of Real-time Consolidation
** Abstract
Real-time Consolidation(RTC in short) is SAP's next generation financial consolidation system, which is built on S4HANA platform and leverages HANA's in-memory technology. 

Unlike traditional standalone consolidation applications, RTC embeds consolidation logic into a centralized financial system. The centralized system we call it Central Finance(CF in short), which makes financial operation, analysis, and planning happens in a same environment, and unifies financial master data and rules across all the local subsidiaries. 

Based on the Central Finance, RTC makes real-time financial consolidation possible in the following ways:
1. Local journals are synchronized into CF in a real-time fashion, so data mapping and consolidation rules will also be applied real-timely at journal level.
2. No additional data copy and batch job is needed when running consolidation. Consolidated results can be made on-the-fly directly based on journal items. 
3. Consolidate results can be traced back to the  original transactions.
4. Local financial close, corrections, and updates can be instantly noticed.
5. Planning and simulation can be made on consolidated results, and vice versa. 

The high level consolidation building blocks (backlogs) includes:
- Data modeling.
- Data collection and validation.
- Inter-company reconciliation.
- Inter-unit elimination.
- Currency translation.
- Reporting.
- Collaborations.
  
*** Administrative Data
| Attribute        | Value                   |
|------------------+-------------------------|
| ACD              | Real-time Consolidation |
| Related Use Case | [[https://sapjira.wdf.sap.corp/secure/IssueHierarchyOverview!default.jspa?projectKey=REALTIMECONSOLIDATION&displayMode=hierarchy][Link to Jira]]            |
| Responsible      | Vincent Zhang           |
| Target Readiness | Incubation              |
| Status           | in progress             |
| Version          | 0.7(Draft Version)      |
| Version History  | [[https://wiki.wdf.sap.corp/wiki/pages/viewpreviousversions.action?pageId=1774869651][Wikipage History]]        |


** Background and Context
Financial consolidation systems are the "engine room" of the corporate finance department, enabling companies of all sizes to comply with regulatory reporting requirements, company law and global accounting standards as well satisfy management's need for periodic management reporting.

But all is not well with standalone consolidation applications that were developed since 1990's. Among them, SAP already has three: BPC, BCS, and EC-CS. Those consolidation solutions are still commonplace in some of the world's largest multinationals. According to one recent research, 47 percent of companies have made substantial investments in their financial close, filling, and reporting. Yet, despite the considerable sums of money invested in the process, management teams across the globe remain dissatisfied with the quality and timeliness of management information.

With the emergence of S4HANA and the concept of central finance, we can build an embedded financial consolidation solution based on them. As financial data is already centralized, it is not necessary to replicate it again to a standalone consolidation system. Meanwhile, RTC can also gain more from the future S4HANA Cloud platform, because of the highly distributed nature of the financial close process. It can help to standardize and harmonize the data collection, improve collaborations, and significantly reduce reporting delay between local operational systems and the corporate consolidation.

*** Number of Customers expected with release now in development 
25+ customers have explicitly stated high interest on Real-time Consolidation. For details, please refer the wikipage: [[https://wiki.wdf.sap.corp/wiki/display/ERPFINDEV/Customer+Engagement+for+Real+Time+Consolidation][Customer Engagement for Real Time Consolidation]].

*** Underlying Platform/Application Server
RTC is built on S4HANA, both On-Premise and Cloud, with On-Premise version delivering first. 

*** Comparison of BPC, BCS, and EC-CS 
**** BPC embedded version
Highly depends on BW technologies,like: virtual info-object, virtual info-provider, real-time cubes, multi info-provider, composite info-provider, aggregation level, planning functions, and so on. Compared with its standard version, the modeling is done in BW, BPC only provides a mapping UI so that the consolidation process know how to consume the BW model. 

The UI contains 2 parts: 

1. WebUI is newly developed using SAPUI5, it is mainly for customizing and administrative tasks.
2. Analytic Office with EPM add-on is for reporting.

**** BCS
BCS is too depends on BW technologies, with the difference is that it is a traditional ABAP application, that all the customizing and administrative UIs are developed using ABAP GUI. But the reporting tools is with BPC, because data is anyway exposed using BW multi-dimension views. 

From functional perspective, BCS is more appeal to large SAP clients, as it has more integration with SAP financial applications. But less attractive for those non-SAP customers or others who need more flexibility. 

**** EC-CS
It is an even older consolidation application that is the predecessor of BCS. Like BCS, it is developed totally  using ABAP, and is fully integrated with SAP financial applications. The difference is that it has nothing to do with BW. EC-CS has its own set of DB tables (ECMCT and ECMCA) to store consolidation data and related customization data.

The limits are mainly on the flexibility and performance. Reporting based on legacy Report Painter is also a drawback.

**** RTC
Regarding with RTC, as the emergence of S4HANA and ACDOCA, both flexibility and performance are well covered by core technologies. Thus its architecture would be more similar with EC-CS. But while EC-CS still has independent tables,like: /ECMCT/ for aggregated data and /ECMCA/ for line item data, RTC can direct use ACDOCA for consolidation. There is no more data copy, and it realizes the combination of OLTP and OLAP. 

As BPC already delivers fancy UI and mature consolidation logic, RTC should achieve reuse. Virtual info-providers and virtual info-objects can be used as the main modeling tool and the intermediary layer which connects BPC and S4HANA finance. Thus BPC UIs and consolidation process can run directly on the actual data.   
 
*** Product Type
Financial analytical application, with data write-back and simulation features.

*** Delivery
| Delivery Artifacts             | Comments                                               |
|--------------------------------+--------------------------------------------------------|
| ABAP & AMDP                    | Main consolidation logic                               |
| HRF/BRF+ rules                 | CDS views, HRF modeling, BRF+ objects                  |
| HANA Calculation View          | Not compliant with S4HANA Guideline, but needed by BPC |
| BW info-provider & info-object | Not compliant with S4HANA Guideline, but needed by BPC |
| CDS View                       | Reporting and Analytics models                         |
| Fiori Apps                     | UI for console, reporting, and analysis                |

*** Business Case
Consolidation is discussed in 80 % of the cases of which we have customer discussions on CF. CF carries all the financial data from the entire system landscape. It is not understood by customers why they need to load the data from somewhere else for the consolidation. Group reporting on CF has limited informative value without consolidation.CF is supplied in real-time. Necessary corrections in local close are updated real-timely. There is no need for the waiting of ETL.

Here are 2 large corporations that both have financial consolidation running on a centralized finance data repository. The requirements are always there,  

**** Sinopec
Sinopec already has a centralized finance system with all its subsidiaries financial data consolidated. AGS team implemented a solution that allow BCS consume this consolidated data directly through BW virtual info-providers and HANA calculation views. Thus reduce the ETL process, and Sinopec already gets benefits from that solution. 

**** Siemens
Siemens has established a so called global template. That means that the group defines the master data centrally, but there is ample possibility for the subsidiaries to extend the master data, for example to create additional accounts in the account hierarchy below a central given account. This is actually a quite frequent approach. Siemens does this with a naming convention: the first 6 digits are reserved for the group, digit 7 and 8 are reserved for the division, the last two digits are reserved for the subsidiary. Exception are all account numbers containing the digit 9, they are reserved for the subsidiary.

*** Main Use Cases / Functional Scope

**** Data Load

**** Data Validation

**** Currency Translation

**** Inter-Unit Elimination

**** Inter-Company Reconciliation

**** Year-End close (pre)consolidation
Traditional consolidation takes days. It needs to extract data from group's sub financial systems, which needs the sub systems finish the closing first. Then transform the data, and load it to the consolidation system. The overall closing and ETL process are very time-consuming. No bother to mention if corrections are needed, the entire process could be re-processed. Corporation stakeholders suffers waiting too long a period for consolidated statements. While Real-time Consolidation can perfectly solve the problem. RTC is based on Central Finance which acts as a central repository for all the financial data, it synchronizes journals from sub systems in a real-time fashion. RTC does consolidations directly based on the central journal repository. There is no additional data replicas needed, Consolidation experts can do pre-consolidations at anytime, without notifying sub financial system to close first.Thus he/she can find problems before year-end closing consolidation actually happens. This permits corrections can be made in sub systems before-hand. Besides, consolidation rules can even be applied in the document posting processes, which guarantee efficient and effective financial controls.

**** Acquisition & Re-organization 
When a new business entity is added/removed from the organization, management teams want see the simulated consolidated results immediately to support decision.RTC can well cope this kind of requirements. 
 
*** List all Required SAP Products/Product Versions to Support the Main Use Cases
S4HANA Finance, Central Finance 1.0, BPC //To-do: versions should be checked

*** Relevant Product Line Architecture Guideline
- [[https://wiki.wdf.sap.corp/wiki/display/SimplSuite/Architecture][S4H Architecture Guideline]]
- [[https://wiki.wdf.sap.corp/wiki/display/SuiteCDS/VDM+CDS+Development+Guideline][CDS Guideline]]
- [[https://wiki.wdf.sap.corp/wiki/display/fioritech/Development+Guideline+Portal][Fiori Overall Guideline]]
- [[https://ux.wdf.sap.corp/fiori-design/foundation/get-started/][Firoi Design Guideline]]
- [[https://wiki.wdf.sap.corp/wiki/display/ERPFINDEV/sFIN+UX+Fiori+Guidelines][sFIN UX Fiori Guideline]]
  
*** Deviations from Product Line Architecture and Product Experience Requirements
| <10>       | <l40>                                    | <l20>                |
| Rule ID    | Deviation                                | Approval Status      |
|------------+------------------------------------------+----------------------|
| OC-AR-2    | No ABAP coding or BW content shall be used for analytic data access or meta data description. BPC embedded version is highly depends on BW,  we have to develop info-objects and info-providers. | Approved by Chief Arch Klensh Christian: HANA Calc view through Virtual Provider is the right track and realistic for the integration with BPC in mid-term (half year).   But in long-term, it is expected to switch to CDS. |
| OC-APP-3   | It is not allowed to create new HANA repository objects because they do not fulfill the life-cycle requirements of Zero Downtime Management (ZDM). Existing HANA content which shall be used in S/4HANA shall be migrated / converted to ABAP managed artifacts. We must develop HANA calculation views because BPC cannot consume CDS views. Virtual info-provider can mapping to a calculation view, it is a mature technology. | Approved by Chief Arch Klensh Christian: HANA Calc view through Virtual Provider is the right track and realistic for the integration with BPC in mid-term (half year).   But in long-term, it is expected to switch to CDS. |


** Boundary Conditions
Real-time Consolidation(RTC in short) runs mainly based on Central Finance(CF in short), which can synchronize journals from all the subsidiary finance systems in a real-time fashion. CF realizes the so-called "Transactional BW"(through SLT and MDG), which breaks through the world of OLTP and OLAP. Compared to traditional ETL-based BW system, CF can significantly improve the raw data quality and reduce the delay of reporting. 
  
In other case, corporations may already have their subsidiaries using a centralized finance system (based on S4HANA finance). Thus the data synchronization is not necessary. RTC then can be run directly on S4HANA finance without the CF.
 
In both cases, RTC requires a centralized finance system that already have all the local journals consolidated in a central repository. It is under that assumption can RTC do further financial consolidation models and processes. RTC will also leverage(or reuse) SAP existing consolidation applications, like: BPC, BCS, and EC-CS. In it's initial releases, RTC will consider BPC as the main consolidation front-end.

*** Quality Attribute Scenarios
**** Data Collection
| <30>                           | <50>                                               |
| *Who initiates activity (interactor)?* | Consolidation operator                             |
| *Addressed part of the system which executes initiated activity (executor)?* | Consolidation monitor: data collection console     |
| *How does the interaction between initiator and executor take place?* | Data Collection is appeared as a consolidation task in the monitor. There could be an overview page to show the status of each unit. If the unit's data collection is not ready, it will be in red light. Click the unit will show details about why this unit is not ready for consolidations, like: data is missing, validation check failed, and so on. |
| *Under which conditions / environment does the interaction take place?* | Mostly, during month-end or year-end closing, the group consolidation operator checks whether the data provided by lock subsidiaries is ready for consolidation. |
| *Result of activity*           | Data is corrected and ready for further consolidation tasks. |
| *KPI*                          | The data collection status is correctly and instantaneously reported to the consolidation operators.The group operator and local operator can efficiently collaborated for resolving the data issues. |

*** Product Standards
~Ensure compliance with product standards. To do so, go through the product standard requirements of category "architecture & technology" in the Product Standard Compliance tool (PSC) before you start defining your architecture and describe in this section how product standard requirements influence the architecture to be defined.~

~Add a link to the PS planning in PSC or describe deviations within this chapter.~

~For further information on product standards, see [[https://portal.wdf.sap.corp/wcm/ROLES://portal_content/cp/roles/cto/DevelopmentResources/Idea-To-Market/Infocenters/WS%2520Office%2520of%2520the%2520CTO/Development%2520Resources/I2M/I2M%2520Product%2520Standards][go/productstandards]]~

*** Technology Decisions
Define which technologies / frameworks are used in which architecture area and for specific topics:

| Architecture                           | Technologies to be Used                              |
|----------------------------------------+------------------------------------------------------|
| Clients                                | BPC, S4HANA applications                             |
| Presentation Layer /  User Interface   | BPC WebUI(UI5), Analytic Office, Fiori, SAPGUI       |
| Business Logic Layer                   | ABAP, AMDP, CDS, Calculation View                    |
| Analytics / Reporting                  | BW info-providers, BEx Query, CDS view               |
| Integration Middle-ware                | Central Finance (based on SLT and MDG)               |
| Business Process Management / Workflow | HRF/BRF+                                             |
| Data Persistence                       | HANA Relational Database                             |
| Development Environment                | ABAP ADT, HANA Studio, BW Modeling tool,Fiori WebIDE |
| Life-cycle Management                  | ABAP CTS, Fiori CI                                   |

*** Reuse
~List the reuse components (engines, objects, intrinsic/common services, 3rd party components) which have to be used for this development program/project/topic/integration scenario. Mention reuse components which explicitly must not be used within this development program.~

General Principles for Reuse
- Take reuse into account in every architecture definition. Well planned reuse has a big positive influence on stability, quality, common look and feel, TCO and TCD of the complete application.
- But consider the costs in relationship to the benefits when reusing a function or feature from others. In especially check if the prerequisites (system, hardware, licenses, implementation and customizing efforts, etc) which are required to use the reuse functions are acceptable for customers. If you answer one of the following questions with yes please consult with your local reuse expert
- Does the used service or functionality force the customer to install an additional system?
- Does the usage of a service or functionality force the customer to implement and customize a new application or technology hub?
- Does the new framework or functionality which is planned exist in a similar version in other areas (Examples are rules engines, business object frameworks, master data, ...)?

The following reuse components must/should/must not be used within this development:

| <15>            | <15>            | <5>   | <5>   | <30>                           |
| Reuse Component | Owned by        | Maintenance Guaranteed? | Usage | Remark / explanation           |
|-----------------+-----------------+-------+-------+--------------------------------|
| HRF 1.6.2       | HRF team        | Yes   | must  | HANA Rule Framework must be used to build RTC's validation engine. The validation engine should permit both high performance and easy rule maintenance for LOB users. RTC use HRF to push rule validation down to HANA level.HRF license should be considered. |
| BRF+ 2.0        | BRF team        | Yes   | must  | BRF+ must be used for the reason of the compliance with S4HANA guideline. HRF cannot be used directly, and must indirectly through BRF+. Compared to HRF, BRF+ is running on ABAP level which could not permits good performance on mass data processing. RTC should combine the advantages of HRF and BRF+. |
| CDS 1.0         | CDS team        | Yes   | must  | Use CDS for modeling when ever possible. CDS is SAP's future business script targets to Cloud. Although it has function limitation and not mature enough, but we should use it as much as possible. |
| Fiori 1.0       | Fiori team      | Yes   | must  | Fiori must be used for all the UI. Fiori is the future S4HANA UI that targets to Cloud. RTC must not use any other Web UI framework, or develop its own framework. Traditional SAPGUI(including HTML GUI) is only allowed for intermediate purpose. |
| IBPF info-objects | IBPF team       | Yes   | must  | IBPF developed a lot of finance planning BW info-objects. RTC can re-used them, or do some extension whenever necessary. Beside, RTC and IBPF should combine efforts so that Consolidation and Planning can happen together. |
| Design Studio   | EPM team        | Yes   | must  | Design Studio is used to create queries. The query can be opened via various analysis tools, like: AO, Fiori Apps, and so on. It is appointed by S4HANA guideline for the only query builder, and will replace BEx in future. |
| BEx Query       | BW team         | Yes   | should | BEx query should only be used when Design Studio is not possible, or for some test purpose. |
| HANA Calculation View | HANA team       | Yes   | should | HANA Calculation view should be only used for the purpose to integrated with BPC. Other cases should use CDS instead. |
| BW              | BW team         | Yes   | should | BW cube should only be used for the purpose to integrated with BPC. RTC should avoid using BW cubes as it violate with S4HANA guideline, and it is not the future. |
| BPC 10.1        | BPC team        | Yes   | should | BPC should be used when ever possible. BPC is the only legal financial consolidation and planning system in SAP. RTC should provide the possibility to allow BPC run on CF seamlessly. In some cases if BPC cannot be used, RTC should also provide some core functionalities that can propose values for customers. |
| CF 1.0          | CF Wdf team     | Yes   | should | CF should be used when customer what its de-centralized finance systems to be somehow centralized. If a totally centralized finance system is not possible, than establishing a centralized journal repository for group reporting and analysis can be realized by CF. RTC then can use the CF to form it's data basis. |
| EC-CS           | IMS team        | Yes   | should | EC-CS is SAP's legacy ERP embedded consolidation application. EC-CS share a lot common features and ideas with RTC, like do consolidation directly on line items. RTC should research, reuse, and adopt EC-CS's functionalities whenever possible. |
| BCS             | IMS team        | Yes   | should | BCS is the legacy consolidation application based on BW that some large corporation clients are still in-use. BCS has more functionalities than BPC, but with old-style UIs and too strict, somehow, too proficient, that not all the customers like it. A lot of BCS features and functionalities could be researched, reused, and adopt to RTC. |

*** Cross-Release Compatibility
~Describe boundary conditions to ensure smooth upgrade / migration.~

~General Principles for Cross-Release Compatibility~

~A new release of an SAP application can always be integrated with any release of any other SAP application that is still in mainstream and extended maintenance. After an upgrade of an SAP application, all previously used scenarios are still available.~

~Release Synchronization schema to be followed (Details see[[https://portal.wdf.sap.corp/wcm/ROLES://portal_content/cp/roles/cto/DevelopmentResources/ReleaseStrategyTransparency/Infocenters/WS%2520PTG/PTG/Operations%2520%2526%2520Program%2520Office/Release%2520Management][/go/releasemanagement]])~

*** Other External Forces / Constraints and Assumptions
~Describe other external forces, constraints and assumptions, which influence or restrict your architecture. This could also be resource, skill set and time line constraints, etc.~

Real-time Consolidation highly depends on Central Finance. CF provides the data bases for the RTC to consume. The successfully implementation of CF puts directly impacts on RTC.

BPC is the only legal consolidation and planning product in SAP. RTC may be bundled with BPC for sales and marketing. If BPC


** Architecture Definition
The architecture chapter describes the main building blocks of the architecture and their relationships. Depict also how the building blocks are integrated with building blocks outside the program/topic.

~For conceptual and technical architecture diagrams use~ [[http://ency.wdf.sap.corp:1080/Modeling/Standard][Technical Architecture Modeling (TAM)]]. 

*** Architecture Context and Overview
RTC mainly interacts with 3 SAP applications: CF, BPC, and IBPF. Each takes a role as following:

1. *CF* provides a data foundation(ACDOCA) for RTC to create models on it.
2. *RTC* enable the user to do typical consolidation preparation, like: data validation, currency translation, Inter-company reconciliation, and so on.
3. *BPC* is the main consolidation tools that can be seamlessly integrated with RTC to do higher level consolidations and eliminations.
4. *IBPF* is highly integrated with RTC. Which can do planning and simulation on the consolidation results, and vice versa. 

Details on each building blocks and their relationships are explained below.

#+CAPTION: Overall Architecture Diagram
[[../image/OverallArchitectureDiagram.png]]

**** Line Item Level Data Integration
Local financial systems synchronize their line items into CF's central journal repository(ACDOCA). The synchronization is realized through SLT. It is a middle-ware which can listen changes at database level and synchronize the updates to CF real-timely. 

Data mapping happens when the newly created items are entering into CF through a master data mapping application called MDG(Master Data Governance). Mater data is mapped from local to group, these could includes: Accounts, Chart of Accounts, company code, cost center, and so on. 

There is also an error handling component(AIF) which centrally process all the processing logs. If error happens, the context is saved for future re-processing. 

This building block is developed and maintained by CF's Waldorf team. RTC is highly depends on this component which permits data quality and timeliness. Meanwhile, RTC provides validation and currency translation services to CF. Additional consolidation rules and currency translations are applied before line items saved to ACDOCA.   

**** Manual Adjustment Posting
Adjustments can be made by posting additional financial documents. These adjustment documents can be either posted in original local financial systems and then synchronized to CF, or posted directly in CF. In both cases, the consolidation validation rules should be applied and existing document posting UIs should be also reuse.

If ACDOCC is used, user has the third option to post documents to ACDOCC only for consolidation purpose. +Then a lighter document posting UI would be introduced by RTC, and less posting validation would be applied.+ This will be detail covered in the =Posting= block.  

**** Flexible Upload
Flexible upload allows user to upload reported financial data, additional financial data, and master data from a file into CF. It should be part of RTC's  =Data Collection=, but as CF also has the similar functionalities, re-usability should be considered. 

But there could be still difference between each other. I suppose CF is using flexible upload mainly for the group reporting, and the data is loaded to ACDOCA. Strict posting validation could be applied in this case; While for RTC, the financial data is uploaded only for the purpose of consolidation, and the data is saved in ACDOCC. Only light validation logic should be applied. 

Whether flexible upload is combined or how to combine still needs further investigation.   

**** Data Collection
Data is collected from all the subsidiaries, or the de-centralized systems through various ways. In the best situation, CF already helps to collect all the data correctly and timely. Then this building block only provides validations to make sure the local financial data is correct and ready for the consolidation. 

But in more realistic cases, data is not that ready enough for consolidation. Some subsidiaries data may not be able to automatically synchronize into CF, or even CF is not the right approach for some instances. In that way, RTC should provide a flexible data upload mechanism which may support spreadsheets upload, manually entering, and web services APIs. Through these flexible interfaces, the raw data will be validated upon consolidation rules, and then posted into ACDOCC.

As said in =Flexible Upload= block, CF may already have covered a lot of data collection tasks. We should try to achieve maximum re-use and combine efforts.

**** Data Foundation
Data foundations are the tables that actual source financial lines are stored. They could be mainly 3 foundation tables:
1. ACDOCA: actual financial journal items.
2. ACDOCC: aggregated journal generated during consolidation.
3. ACDOCP: aggregated journal generated during planning. 

There are 3 types of data would be stored in RTC:

*Reported financial data on line item level* | 
This is the data which central finance takes care of already: the FI line items. This is the basis of the consolidation, and normally comes from an FI system. However, we have to take care of special situations and the transformations that typically take place when the data is copied from the local accounting to the group accounting.

*Reported financial data on aggregated level* | 
There will be most likely cases where the data is not provided on line item level. Examples are very small subsidiaries, that just do not do accounting on such a detailed level (they might just use a PC program). Or I remember one case where a joint venture was managed not so jointly, so one of the two parents did not get the detailed information, but only the high level aggregated data.

Saving such kind of aggregated data to ACDOCA is not that easy, and a separate aggregated table, like ACDOCC, would be more achievable.  

*Additional data* | 
Not all data is in ACDOCA, and not all data in the full detail needed by consolidation. For example we do not have the investment information in ACDOCA. Or Financial Services store the details about the customer accounts in their own table, and only have an aggregated view in ACODCA. Another example is sub-ledgers which are not (yet) integrated into ACDOCA.

How to save this additional data? Extending fields on ACDOCA and ACDOCC, or join additional tables? Either need model to be adjusted on DB level. Ensuring the flexibility and performance at same time on the enrichment of data foundation is a big challenge(see next chapter "Data foundation enrichment").

**** Data Exposure via BW/CDS
Multi-dimension views can be created either using BW info-providers or using CDS analytic views. They are both underlying modeling technologies that Data modeling tool depends on. The BW info-provider is only used to integrate with BPC and BCS. As both of them are build on BW components. 

CDS analytic views are preferred as it is SAP's future modeling scripts, and the only modeling technology allowed by S4HANA guideline. The expectation is that BW can support CDS well, so that there is no need to support 2 different modeling technologies. 

HRF vocabulary is also a data exposure technology. But it is for rule definition and execution. 

**** Data Modeling
Data modeling is to define fields and rules for a consolidation campaign. From technique point of view, data modeling is to create multi-dimension views and consolidation rules based on foundation tables. These activities could be simplified by consolidation modeling tools. 

These foundation tables includes: ACDOCA, ACDOCC, and other data sources like ACDOCP (or customer specific data extensions). They are used to generate a fact view.

Master data views(includes Hierarchies) which are generated upon existing master data tables will then be associated to the fact view to form a multi-dimension view. The multi-dimension view can then be used for reporting and analytics. Master data could be freely extended, both horizontally and vertically, according to various consolidation requirements.

The consolidation customization data is used to define consolidation Units, Groups, and Scope. A =Unit= can be only assigned to one =Group=; =Group= can also contains sub-groups, thus to from a consolidation hierarchy. Nodes in the hierarchy could be time-dependent or version-dependent. Details can be found in building block "Consolidation Unit/Group/Scope" 

Fields in fact view are implicitly assigned to different roles. Roles include: Key, Consolidation dimension(unit), Account, Currency, Sub-assignment, Version, and so on. When defining CDS views, we can add an abbreviation prefix to each field's semantic name. Each field's role is then assigned without having to using an additional mapping table. Following table indicates how we category Fields to their roles:
| Field Role          | Abbr. Prefix | Semantic Name Example |
|---------------------+--------------+-----------------------|
| Key                 | K            | K.FiscalYear          |
| Account             | A            | A.AccNum              |
| Transaction         | T            | T.PostingLvl          |
| Currency            | C            | C.GroupCurr           |
| Unit                | M            | M.BaseUnit            |
| Consolidation Unit  | U            | U.RCOMP               |
| Partner Unit        | P            | P.PartnerComp         |
| Consolidation Group | G            | G.ConsGroup           |
| Account Assignment  | H            | H.SubCategory         |
| Amount              | V            | V.GroupCurrAmount     |

Those consolidation customization data are exposed via CDS views, which then can be associated with the fact view for reporting, or assigned to HRF vocabulary for rules definition. Although the consolidation hierarchy are changed frequently, but the meta of these objects are rather stable. So both the CDS views and HRF vocabulary can be pre-delivered as static artifacts (colored with yellow). 

Unlike consolidation customization view and master data view, the meta of fact view is designed for flexible customization and frequently changing. Users may add/delete new fields according to their needs. So the fact CDS view and corresponding HRF vocabulary should be generated by modeling program dynamically. For details about objects and artifacts involve in modeling process, see following diagram:  

#+CAPTION: Data Modeling Diagram
[[../image/DataModeling.png]]

This building block is dotted because it can be replaced by BPC's modeling tool. In case BPC is not possible due to release strategy or other reasons, RTC should provide a flexible modeling tool. In both cases, RTC should provide a set of modeling APIs that can generate CDS views, assign CDS views to HRF vocabulary, and allow other consolidation tools to integrate with. 

**** Consolidation Unit/Group/Scope Definition
Consolidation unit is the smallest element in a consolidation hierarchy which forms the basis for consolidation. You can define the role of consolidation unit for entities like:  =company=, =profit center=, =cost center=, =business are=, =plant=, and so on. If more than one entities are defined as consolidation unit in a consolidation area, then a matrix organization is portrayed.   

Consolidation group groups consolidation units for the purpose of consolidation and reporting. A unit can be only assign to one group, and a group can be assigned only to another group. At the end, there should be a root group. Thus a consolidation hierarchy is structured which can be based on different perspective: regional, product,or organization structure. 

Consolidation scope is a sub-tree of the hierarchy, which only includes those nodes that are relevant to this consolidation campaign. Irrelevant nodes (like 10% own of the entity) are removed from the scope.

There are also consolidation version, financial statement item, sub-assignments, and so on. They are all consolidation specific customizations. These customizations are stored in a set of customization tables. Based on these customization, consolidation monitor, inter-company reconciliation and reporting can be portrayed correctly. 

**** Inter-Company Reconciliation 
Inter-company Reconciliation (ICR in short) provides you with periodic control over accounting documents that describe the accounting transactions within a corporate group. Designed to reduce the differences in corporate group consolidation, this application in Financial Accounting allows early analysis in the closing process to avoid differences altogether and to reduce the deadline pressure that normally arises during the end of a closing period.

ICR operates on the level of companies and its trading partners. To avoid currency conversion differences, the documents are reconciled in the *transaction currency*. Both individual companies and their parent companies benefit from ICR. Individual companies benefit from paired documents because they need to ensure that their own documents from accounting transactions correspond to the documents of internal trading partners. This helps avoid delays and disputes when payments are processed. Their parent companies can then make a global check on the reconciliation results for all the companies.

You can regard ICR as a special process that belongs to data collection. It is such a common usage that SAP already has this feature as a separate component called [[https://help.sap.com/saphelp_erp_fao_addon20/helpdata/en/d7/5a7c525ae17154e10000000a44176d/frameset.htm][SAP ICR]]. ICR supports the following three reconciliation processes:

1. *G/L open items reconciliation.* This process is for reconciliation of open items if most of your inter-company receivables and payables are posted to G/L accounts.
2. *G/L account reconciliation.* You use this process for reconciliation of documents that are posted to accounts which do not have open item management. This process is mostly used for reconciliation of profit and loss accounts.
3. *Customer / vendor open items reconciliation.* You use this process for reconciliation of open items. Choose this process if most of your inter-company receivables and payables are posted to customer and vendor accounts.

Currently, ICR has both dynpro UI and webdynpro UI, but without Fiori. Evaluation should be made to check if current webdynpro app can be enhanced, or new Fiori UI could be developed. The new ICR UI will access ACDOCA data through CDS exposure, and need the consolidation scope definition and reconciliation rules to be defined in the validation engine. 

**** Inter-Unit Elimination
When we talk about consolidation, we also means elimination. Consolidation and elimination are two actions that usually happen together. At most time, we simply called it "consolidation". Consolidation means do aggregations on the amount that belongs to the same dimension group. Elimination means some related amounts should be eliminated to avoid unnecessary counting. Elimination usually happens between 2 trading partners, for example: Partner A sold something to partner B with amount 100 dollars. Both A and B are belong to the same business group. So, from group's point of view, the transaction amount $100 should be eliminated.

Elimination usually exists between a pair of consolidation units, such as:
| Business Relationship                      | Inter-Unit Elimination                     |
|--------------------------------------------+--------------------------------------------|
| Payables & Receivables                     | Elimination of IU payables and receivables |
| Revenue & Expense                          | Elimination of IU revenue and expense      |
| Revenue & Expense from Investment Holdings | Elimination of investment income           |

Prior to running inter-unit eliminations, you can use reconciliations to determine any elimination differences without having the system post elimination entries. By doing this, you can correct posting errors in the reported financial data, or manually post standardizing entries. So posting functions will be called either automatically or manually during inter-unit elimination. 

**** TODO Posting
**** Validation Engine
Validation Engine is the core of financial consolidation. It is used for storing and running consolidation rules, and rules could be applied in all other building blocks. Easy customization and high performance of applying rules are the key targets that this building block should achieve.  

Validation Engine is built on existing rule frameworks HRF and BRF+. HRF stands for Hana Rule Framework. Rules maintained in HRF can be applied directly in HANA, which permits good performance. BRF+ stands for Business Rule Framework plus. BRF+ is an ABAP-based rule framework. There is a road-map that HRF and BRF+ will be merged into one. But currently HRF can be integrated into BRF+ in some degree.

How we use HRF combined with BRF+ is still under research.
 
**** Validation Rules Customization
HRF has 2 kinds of rule editors, one is Text-Based Rules, and the other is Decision Table. HRF team has made them  UI5 components, so that it can be easily integrated and reused by other applications. 

*Text-Based Rules:*
Simple, natural, and intuitive business condition language (Rule Expression Language)

#+CAPTION: Text-Based Rules
[[../image/TextRuleEditor.png]]

*Decision Table:* 
Simple and intuitive UI control that supports text rules and decision tables

#+CAPTION: Decision Table
[[../image/DecisionTable.png]]

While RTC can leverage HRF's high performance and intuitive rules editor, how to map existing rules of BPC and BCS, or even 3^{rd} party consolidation applications into HRF is still a big challenge.  
  
**** Currency Translation Engine
Currency translation is based on the HANA function: *CURRENCY_TRANSLATION*. The function use the exchange rates in table: TCURR. TCURR and other related tables forms SAP ERP's exchange rate repository. Real-time consolidation should be connected to the exchange rate repository. 

There are 3 kinds of exchange rates that consolidation needs:
1. Average rate
2. Transaction rate
3. Reporting rate

The choice of different type of rates is based on type of accounts. The currency translation engine should choose the right rate with high performance and high customization. HRF's decision table could be used in such case. 
   
**** Currency Translation Rules Customization
As describe above, HRF Decision table could be used to maintain the currency exchange rules. It should be easy to mapping exchange rate rules to decision table. 

API should also be provided to allow external rate repository to be imported into HRF. 

**** Consolidation Monitor 
Consolidation monitor provides a central place to view consolidation hierarchy, groups, and units. You can also executes consolidation tasks(like data collecting, standardizing, and elimination), and monitor the progress of execution.

How consolidation processes depends on the consolidation hierarchy defined, tasks assigned and the rules maintained. Customers usually define consolidation rules based on their own needs. There are also standards to follow, like: GAAP and IFRS, which are legal requirements that all the corporations must follow.

There could be difference generated during consolidation. For example, when local currency amount is translated to group currency amount, due to the fluctuation of currency rate, the translated group amount could be unbalanced. Thus, adjustment documents would be posted automatically, and the difference amount will be recorded to an account that specified in the rules. 

The whole process may run in hours in traditional consolidation applications. But within Real-time Consolidation, it should be done in minutes(without scheduling any batch jobs). Sometimes, it could be run on-the-fly without doing any document postings. For example, when the operator wants to see updated results after small adjustments or new journals come in.   

This building block is the main entry point for the users. It should be a Firoi App or can be replaced by BPC web client. 

**** Reporting
Reports or queries are based on multi-dimension views that exposed either by BW or CDS. Tools like BEx Query Designer and Design Studio could be used to create queries based on multi-dimension views. Those queries can be then consumed by AO and Fiori.

Reports could be organized by consolidation hierarchies.

There are report to report navigation called [[http://help.sap.com/saphelp_scm700_ehp02/helpdata/en/4a/5b96c6517f2e24e10000000a42189b/content.htm?frameset=/en/4a/5b96c6517f2e24e10000000a42189b/frameset.htm&current_toc=/en/b2/259b06d406454fa8429240ecaed4f6/plain.htm&node_id=123&show_children=false][Report-Report Interface]](RRI in short). RRI allows you the flexibility to call a jump target (receiver) on-line from a BEx query (sender) within or outside of the BW system. Jump targets that have been assigned to a BEx query can be selected in BEx Web applications and in the BEx Analyzer. You can access them from the context menu under the Goto function.

Analytics Office also support RRI just like BEx Analyzer. Fiori Apps should develop corresponding navigation features to existing list view reports or detail transactions. The consolidation trace back requirements are actually realized through these report-to-report navigations. 
  
*** Main Architecture Challenges and Decisions
**** Have to use calculation views and BW content
HANA and BW content is not allowed in S4HANA guideline. This is because they are not targets to Cloud. But Real-time consolidation has to use them because it has to integrate with BPC. While BPC is SAP's only legal consolidation product, it is a sub-component of BW, and fully build on BW info-providers. Ask BPC to support CDS in short term is impossible. 

| <15>            | <50>                                               |
| *Decision*      | We have to use HANA calculation view in short term. But it is expected to switch to CDS view. |
| *By*            | Chief Arch: Christian                              |
| *Date*          | <2015-11-18 Wed>                                   |
| *Description*   | HANA Calc view through Virtual Provider is the right track and realistic for the integration with BPC in mid-term (half year).   But in long-term, it is expected to switch to CDS. |

**** Should integrate with BPC
BPC is the only legal consolidation app in SAP. BPC is developing its embedded version of financial consolidation system that can real-timely access financial data through BW virtual info-provider. Besides, BPC has an existing UI based on UI5. We should leverage BPC's existing assets and combine development work. So that RTC can be brought to market as soon as possible. 

| <15>            | <50>                                               |
| *Decision*      | RTC should integrated with BPC as the main consolidation tool |
| *By*            | PMO                                                |
| *Date*          | <2015-07-01 Wed>                                   |
| *Description*   | BPC will be the main consolidation tool. RTC will do the data provision on S/4 HANA Finance for BPC. |

**** Consolidation and Planning should be considered together
Financial consolidation and planning share the same architecture when integrated with BPC. We should work closely and combine effort. 

| <15>            | <50>                                               |
| *Decision*      | RTC and IBPF should work closely and combine effort. |
| *By*            | Chief Arch: Christian                              |
| *Date*          | <2015-09-10 Thu>                                   |
| *Description*   | Financial consolidation and planning share the same architecture when integrated with BPC. We should work closely and combine effort. |

**** Where to store the consolidated results
Helmut has described 4 options to store consolidated results:
1. Consolidation results will be saved to an ACDOCA extend ledger.
2. Consolidation results will be saved to an ACDOCA independent ledger.
3. Consolidation results will be saved to ACDOCC, a new table for consolidation.
4. Consolidation results will be saved to a BW Cube.

*ACDOCA Extend Ledger* 
The data from the subsidiaries will reside completely in one ACDOCA Ledger, all eliminations and adjustments are posted in an extend ledger. The Pros is that SFIN functionalities can be reused; While the Cons are the requirements of strictly alignment of master data, and save to ACDOCA via posting interfaces(see next section).

~Here should have some simple explanation on what is extend ledger, and what is the difference between standard ledger. Extend Ledger is now changed to the name Special Purpose Ledger, which is of the application component FI-SL. You can define ledgers for reporting purposes. You can keep these user-defined ledgers as general ledgers or subsidiary ledgers with various account assignment objects. Account assignment objects can either be SAP dimensions from various applications or customer-defined dimensions. You can refer [[http://help.sap.com/erp2005_ehp_04/helpdata/en/da/6ada3889432f48e10000000a114084/frameset.htm][SAP online help]] for more details on Special Purpose Ledger.~

*ACDOCA Independent Ledger*
The data from the subsidiaries will reside in ACDOCA. But we will use a different ledger and different master data for consolidation. We need to extend ACDOCA access so that when reading data from ACDOCA for that ledger the data from the subsidiaries in the different ledger can be added via a view (kind of a visualized ledger). This is already been in discussion to handle the challenge of integrating ledgers like Financial Services that want to stay in their own tables, but also want to eliminate the replicated or aggregated footprint in ACDOCA. This is however not available yet.

The Pros compared to ACDOCA Extend Ledger is the decoupling of master data, but the Cons is that the technology is not yet available.

*ACDOCC*
The data from subsidiaries will reside in ACDOCA. We will use a (more or less complex, but definitely flexible) view on top of ACDOCA. All data created by consolidation is stored in a new table ACDOCC.

The Pros compared the former 2 options are that fields in ACDOCC can be defined (and extended) independently from ACDOCA, and records created by consolidation functions can just be stored, no FI posting logic to be considered. The Cons are that separated data set causes it hard to find relationship between group and local data, and cannot reuse SFIN existing reports and Firoi Apps.

*BW Cube*
Similar to Planning we could store the data created by consolidation in a BW cube, while we read the subsidiary data from ACDOCA via a HANA View.

The Pros compared the former 3 options is that it is most flexible in modeling. But the Cons is that it is not the with S4HANA targets Cloud. 

| <15>            | <50>                                               |
| *Decision*      | The optimal solution would be probably to enable an extend ledger for ACDOCA for those customers which are already advanced enough to use this, and to provide ACDOCC for all others. If we can do only one, the reasonable approach in terms of customer base is probably ACDOCC. |
| *By*            | Helmut Hoffman                                     |
| *Date*          | <2015-12-11 Fri>                                   |
| *Description*   | Using an Extend Ledger on ACDOCA is the most visionary approach. But as such it contains also huge risks. Customers might not be able to harmonize the master data and transactional data in such a degree as is needed, it might even go to a decision between enabling the central finance for consolidation or for centralized operational processing. ACDOCA also contains technological challenges, in particular the question of how to do updates via the posting interface. We should avoid investing into a BW cube, this is a dead horse in light of S4HANA and B4HANA. |

**** Posting to ACDOCA via standard interfaces
When storing data in ACDOCA we should use the FI posting interface to ensure that only correct data is stored in ACDOCA. If for example data is stored in ACDOCA that violates referential integrity assumptions that are included in views, that might break HANA Views, generic programs running over the entire ACDOCA like migrations and other tools. In particular BPC is a fairly generic toolset, where the customer can define also rules that would violate these integrity assumptions. Thus going via the standard FI posting interfaces seems necessary to protect the application.

But going through the FI posting interfaces has some implications:

- Write back must be done via application ABAP coding (write back class in virtual provider or write back class in current planning enabled CDS View), not via a HANA view, not via a standard implementation for a BW infoprovider

- The posting logic might change the lines created by the consolidation engine. For example additional fields might be derived. Or tax lines might be created. We can define a reduced posting logic for consolidation mainly focusing on the referential integrity; it is not clear how far this can go. Certainly the consolidation application expects that the data is stored exactly the way it is created by the consolidation application, without any further modifications or enrichments

- Posting via ABAP and FI posting interface will have a performance impact. It also means that the consolidation can not be pushed fully to the HANA, only the calculation, but not the posting. If the data would be stored directly on a standard database table like a BW cube or ACDOCC, also the update could be done on HANA, having the entire processing in HANA.

| <15>            | <50>                                               |
| *Decision*      | Avoid automatic generated document posting to ACDOCA, using an additional Table ACDOCC instead. The ACDOCC approach can reduce the impact from the posting logic, and can improve consolidation performance by allowing both calculation and posting into HANA. |
| *By*            | Helmut Hoffman                                     |
| *Date*          | <2015-12-11 Fri>                                   |
| *Description*   | In case ACDOCC is not allowed, or customer want to use a extended ledger to save all the consolidation results. Then we might still need post through standard interfaces. The performance impact should be further investigate. For example, we can reduce the possibility that consolidation process generates adjustment documents. The adjustment documents could be posted to ACDOCA in phases before consolidation process happen. |

**** The data collection depends on Central Finance
There are lots of experiences how data is collected from local financial systems to form a consolidation data base. 

*EC-CS and FI-LC*
have the possibility to define a real-time update. Then every FI posting will also update the totals in consolidation, or even create a line item in consolidation.  There are several mappings of master data possible, for example, operation account to group account, encoding of various accounting objects into the field sub-item, and filling of custom consolidation fields via user-exits. 

The real-time update does have some enthusiastic customers using it. However, the usage is small for two reasons:

1 You have to run everything in one system.
2 The master data must be fairly aligned, the mapping capabilities are limited.

*Load from Data Stream in SEM-BCS*
SEM-BCS allowed the customer to use a BW extractor, define the mappings in some customizing and then load the data into BCS at periodic intervals. This was not used very often. It is too difficult to define the rules and to understand, where the data is coming from

*Delta Load in SEM-BCS*
BCS also offers the possibility to load the data from FI via an extractor into an operational ODS and then to transfer it from there into BCS. Delta load is supported, so a continuous data transfer is possible.

A direct load into BCS instead of the intermediate step with the operational ODS was rejected by the customers with the reason that they need the intermediate ODS in order to understand how the data in BCS and the operational data relate to each other, the intermediate result in the ODS makes the transformation traceable.

| <15>            | <50>                                               |
| *Decision*      | Central Finance makes sense to unify the master data when data collection is made real-time. But it will make tracing back to original transaction difficult. It is also not realistic to force all the company codes into a same corporate master data. There should be auxiliary data collection methods and master data extension solutions provided by RTC. |
| *By*            | Helmut Hoffman                                     |
| *Date*          | <2015-12-11 Fri>                                   |
| *Description*   | The data in the group close and in the local close typically do use quite different master data. To some extent companies are trying to avoid this, by using central master data, but resistance is large. The need for specialized master data can be channeled by using defined extension mechanisms, but there are also cases where unification just is not possible, for example if the regulatory bodies define certain master data. With the central finance approach, it does make sense to unify the master data when replicating into the central finance system. Theoretically, you could just do a 1:1 replication, each company code replicating into its central finance with its own master data, but that would defeat some of the purposes of a central finance system like an early overview over the data. However, it is not realistic to force all company codes into the same corporate master data in central finance, as this on the one hand would make it difficult to trace back the data to the original posting. At the same time it would make it difficult to move operational processes like payment to the central hub, as the local extensions/changes to the master data are likely to affect these operational processes. The central finance approach makes it clearly more probable to have data in ACDOCA which can be used right away for consolidation, but considering the situation today, where massive data mapping, data recoding and data enrichment is done for consolidation, it seems unlikely that this will be the case for all, or even the majority of the customers. |

**** Master data extension
Master data need to be easily extended and involved in consolidation calculation. There are 4 potential options:
1. RTC creates extension tables, and join with existing tables.
2. RTC creates append structure on existing tables.
3. RTC provides a generic field extension solution.
4. Wait for BPC's generic field extension solution.

The =extension table= solution is flexible in that the different join conditions can be defined. For example, accounts master data =SKA1= can be joined with an extension table with account group (not the key account number). This way, the efforts on the extension fields maintenance can be reduced. 

We will provide a standard extension table with key-joins. And we document on how customer can create its own extension tables with flexible-joins. 

Additional master data can be created using maintenance views. For example, customer wants an account to record differentials after currency translation, he must create the technique account in standard maintenance view, then he should maintain extension fields. Tools/UIs could be designed for the user-friendly of the master data maintenance. If possible, we should pursuit master data maintenance through BPC's existing UI or API.

Hierarchy can be extended in the same way with some ABAP programming.

The =append structure= solution is less flexible comparing with =extension table=, but more straight forward in that user can maintain these extended fields using existing master data maintenance UI (need some enhancement). 

Option 3 and 4 are pursuing more generic extension solutions. If we want the master data extension in RTC side, then  the =end-user extension tool= is expected. The tool allow user extend fields from Firoi UI in a "What You See is What You Get" fashion. It is heard the tool will be released in this year. 

If on the other hand, we think the extend fields is more reasonable to be stored in BPC side. Then, we can leverage BPC's future =local info-objects=, which can merge the data with those virtual info-objects provided by RTC. But BPC can not give a confirm date on when it is available. It is not expectable in recent 1~2 years. 

| <15>            | <50>                                               |
| *Decision*      | We choose =extension table= solution for the first release. |
| *By*            | Vincent Zhang                                      |
| *Date*          | <2015-11-20 Sun>                                   |
| *Description*   | The =extension table= is the most flexible and need less implementation effort. We will then evaluate more generic solutions mainly test the =end-user extension tool=. If BPC gives the a date on its =local info-object=, then it is still under consideration. |

**** ACDOCA and ACDOCC extension
It is very possible that additional financial data is needed in a consolidation campaign. Customer may store the additional data by extending fields on ACDOCA or ACDOCC. Thus the data model based on them can also be extended correspondingly. I suppose the API and UI extension could be handled by =end user extension tool=.

If additional data is stored in other tables, then associated tables with ACDOCA or ACDOCC through DB join view is also very straight forward approach. Then the consolidation model tool should have the ability to recognize the joined fact views. There could be performance drawback in this situation, as join 2 large tables is not a good idea in HANA.

In both extension options, these new added fields should be assigned with consolidation specific roles, like: version, account, entity, and so on. How this role assignment is done is still under investigation. 

| <15>            | <50>                                               |
| *Decision*      |                                                    |
| *By*            |                                                    |
| *Date*          |                                                    |
| *Description*   |                                                    |

**** Rule framework
Consolidation rule is an important part of financial consolidation. In S/4 guideline, BRF+ is the only permitted rule framework. But BRF+ is an ABAP rule framework, if you want to leveraged HANA, you can only use HANA Rule Framework(HRF) through BRF+ interfaces. BRF+ and HRF already planned a road-map to make the 2 frameworks merged into one. 

RTC requires data validation based on a large amount of data. So using HRF is an idea choice compared with BRF+.But that also means there will be gaps among RTC, BRF+, and HRF. For example, if RTC finds a feature is missing, then there could be the BRF+ API issue, or the HRF issue. A lot of communication work will be raised. 

Current situation is that HRF is still in its initial releases. Only 6 internal dev teams use it. Although BRF+ wants to integrate HRF, but the API is not friendly enough. There is indeed some function missing at BRF+ API level. To RTC, 2 options could be considered:
1. Co-work with BRF+ to improve the existing APIs.
2. By-pass BRF+, call HRF json interface directly. 

If we go through the first option, it complies with S/4 Guideline, but may hinder RTC's development process. We already did a PoC, and the result is to find currently BRF+ API is still not ready for HRF. A lot of HRF features like =Alias=, =Data objects=, and so on are missing, which on the other hand, are required by RTC.

The second option is the faster approach. While it violates with S/4 Guidelines, we can still apply the deviation if we have listed good reasons. Meanwhile, we should keep in mind that some facility features could be provided by ourselves. This will at least includes: Transport of contents, DDIC conversion, Security. 

| <15>            | <50>                                               |
| *Decision*      |                                                    |
| *By*            |                                                    |
| *Date*          |                                                    |
| *Description*   |                                                    |

**** Push down to HANA
RTC should push down most of its calculation logic to HANA, or the real-time target cannot be achieved. The challenge is that S/4 HANA is still using ABAP as the main application programming language, while RTC should avoid processing massive data in ABAP context. 

We may using CDS views to achieve some basic analysis logic, but CDS still has a lot of capabilities gaps within consolidation. And CDS is designed for a universal modeling script, it is anyhow not a real programming language.

AMDP can be used to complement CDS. As HANA sql-script has a rich pool of functions, and can define intermediate variables. Besides, AMDP can be used to insert/update data which CDS cannot do it. 

HRF is a rule framework runs on HANA. It is suitable for defining financial consolidation rules. The mechanism under the hood of HRF is to generate DB procedure and views based on JSON files that have well-defined schema. It provides somehow a dynamic programming approach at HANA level. The DB procedure and views can be consumed by CDS, AMDP, and ABAP. 
 
In the best situation, a feature can be realized fully using HANA artifacts. But if not, ABAP can used as a glue language to join all the HANA artifacts together, and to be a interaction layer between UI and back-end. In short, we should avoid massive data processing in ABAP context.    

| <15>            | <50>                                               |
| *Decision*      |                                                    |
| *By*            |                                                    |
| *Date*          |                                                    |
| *Description*   |                                                    |

**** UI technology
RTC will reuse BPC's UI as much as possible. But more or less, RTC could deliver some UI artifacts:
1. *Consolidation Monitor*: for data collection, currency translation and Inter-company reconciliation.
2. *Data Modeling*: for CDS and HRF vocabulary generating. 
3. *Consolidation Customization*: define version, dimension, and hierarchies.
4. *Document Posting*: a simplified document posting UI for consolidation.
5. *Flexible Upload*: allow company to upload reported data through excel sheet.
6. *Master Data Maintenance*: maintain master data
7. *Rule Maintenance*: maintain rules for data validation, currency conversion, and automatic postings.
8. *Reporting*: some group reports, trace-back reports, and ICR comparison reports.   

Fiori should be the first option according to the S/4 HANA guidelines. But considering the team capability, we are lacking of Fiori development resources. But if we choose ABAP dynpro, although we can gain some efficiency, we will lose the cloud target. Besides, the ABAP dynpro is less attractive.   

The compromise approach is to mix use of different UI technologies in different phases. And try to find the best solution along with the development progress.

| <15>            | <50>                                               |
| *Decision*      | First try to reuse BPC's existing UI. If not possible, try to use Fiori and ABAP dynpro. Firoi is for LoB user oriented, while ABAP dynpro is for customization and master data Maintenance. |
| *By*            | Team                                               |
| *Date*          | <2016-01-24 Sun>                                   |
| *Description*   | Consolidation Monitor, Data Modeling, and Document Posting should reuse BPC's existing UI, RTC only need to provide suitable API for BPC's consume. Customization, Master Data Maintenance, and Flexible Upload can use ABAP dynpro first, as using the auto-generated Maintenance view is the fastest way. Later these UIs should be moved to Fiori. Rule Maintenance need to be achieved using Firoi, as HRF provides UI5 controls which can be easily integrated into Firoi UIs. Reporting can be realized using either way. Analytic Office is also an auxiliary front-end tool for massive data reporting. |

**** Consolidation Hierarchy
| <20>                 | <50>                                               | <50>                                               |
|----------------------+----------------------------------------------------+----------------------------------------------------|
| Solutions            | Pros                                               | Cons                                               |
|----------------------+----------------------------------------------------+----------------------------------------------------|
| BW hierarchy         | Support both version and time dependent.           | BW persistency is client-independent.              |
|                      | Native OLAP engine based on BEx Query.             | Not easy to read/write data from out-side BW.      |
|----------------------+----------------------------------------------------+----------------------------------------------------|
| SET hierarchy        | Generic modeling with fundamental framework.       | Cannot model same entity on both group node and leaf node. |
|                      | Support both version and time dependent.           | Need to build web maintenance UI.                  |
|----------------------+----------------------------------------------------+----------------------------------------------------|
| HR Org.              | Very good support on time-dependent on node level. | No version dependent.                              |
|                      |                                                    | Maintenance UI still based on SAPGUI.              |
|                      |                                                    | UI is too HR specific and not easy to rebuild UI.  |
|                      |                                                    | Not allowed to build new entity type.              |
|----------------------+----------------------------------------------------+----------------------------------------------------|
| Universal Hierarchy  | Version / time dependent based on requirements.    | High effort.                                       |
|                      | Multiple entity types based on generic persistency. |                                                    |
|                      | Single persistency and single maintenance UI.      |                                                    |
|----------------------+----------------------------------------------------+----------------------------------------------------|
| Cons. Hierarchy      | Support both version and time dependent.           | Create from scrach for both Backend & UI           |
|                      | Support multiple node types in one hierarchy.      | High effort                                        |
|                      | Support cross area (e.g.: Controlling Area) in one hierarchy |                                                    |
|                      | Specific to consolidation but still could be flexible |                                                    |
|----------------------+----------------------------------------------------+----------------------------------------------------|
*** Integration with Other Systems
**** Integration with CF
CF does most of the data collection tasks for RTC. To more seamlessly integration, consolidation logic should evenly embedded in transactions and executes when transaction happens. Thus some data validation and substitution should be applied during document posting. RTC will provide such kind of APIs.

Reporting should also combine the operational reports, consolidated reports, and  planning/simulation reports. Thus how data is accessed and processed among ACDOCA, ACDOCC, ACDOCP, and others need re-thinking.  

**** Integration with BPC
RTC acts as a data provisioner for the BPC to consume data in S/4 HANA Finance real-timely. We can re-use BPC's existing consolidation logic and UI.

RTC can also do some consolidation preparations, like: data collection and validation, currency translation, Inter-company reconciliation and elimination, before the data arrives at BPC to do further consolidation tasks.   
**** Integration with IBPF
IBPF stands for =Integrated Business Planning for Finance=. RTC shares the same architecture with IBPF when integrated with BPC. Both are based on BW virtual info-provider and virtual info-object. We could share most of the info-objects for the master data. Besides, we can think more on how we combine data in ACDOCC and ACDOCP, so that consolidation can run on planning data, and planning can run on consolidated data. 
**** Public APIs and Contracts
The following table lists all public APIs which are offered, be it newly created API or changes on existing APIs
| <20>                 | <15>            | <10>       | <45>                                          |
| Name of API          | Type            | Changed/New | Description                                   |
|----------------------+-----------------+------------+-----------------------------------------------|
| Consolidation Fact Table View | BW info-provider | New        | Provide a BW composite provider to let BPC consume real-time data in ACDOCA |
| Consolidation Master Data View | BW info-object  | Changed    | Consolidation master data is provided to BPC through virtual info-objects. Virtual info-objects is based on HANA views, and can access ERP master data directly. It is expected that Planning and Consolidation should share a same set of virtual info-objects. The existing info-objects developed by IBPF could be extended to fulfill both requirements. |
| ACDOCC posting       | ABAP-based      | New        | Provide data validation and posting to ACDOCC logic in the write-back class, flexible upload, and other external processes. |
| Validation & Substitutions | ABAP-based and HANA View | New        | A set of APIs that can be embedded in consolidation tasks, existing ABAP codes, and CDS views through join/union/association. They provide data validating and substitution services which the provides LoB users exists to maintain their rules. |

*** TODO Security
~Describe how the architecture protects the software against attacks or misuse.~

~To do so, define how communication channels (protocol, data, ...) are protected. Describe how authentication, authorization and logging are performed. Consider architecture requirements pertaining to confidentiality, integrity and availability.~ 

*** TODO Deployment and Operations
~It is recommended to work with the local Technical Component and Delivery Architecture (TCDA) team on defining deployment and operations architecture. Contact is the "Delivery Architecture Engineer" maintained in [[https://ifp.wdf.sap.corp/sap(bD1lbiZjPTAwMSZpPTEmcz1TSUQlM2FBTk9OJTNhcHdkZjU3ODJfSUZQXzAxJTNhWEhRWUJUMFlnaXNneEZlWWZTemIwR1FhWnZxaXotY2lkX1Z3TUF0Zy1BVFQ=)/bc/bsp/sap/zpr/default.htm][program repository]] entry of your program.~

**** Deployed Component Structure and Deployment Options
Show all interdependencies of (groups of) software components using a package diagram (TAM). Assign the components to software layers, for example see: https://wiki.wdf.sap.corp/display/archGov/Software+Layers

Describe software component structure, package structure and their deployment options. Deployment options describe the different possibilities how the software components can be distributed across different systems. Indicate cross-component communication. Mention explicitly, if there are new dependencies between software components.

Describe deployment unit and process component structure if relevant.

**** System Landscape
Describe typical system landscape required to run the software developed within this program productive at a customer site. Show how the main deployable building blocks are distributed within that landscape. Determine which landscape components are mandatory and which are optional to run the software

**** Operation Concept
Describe how the planned software is operated and estimate the impact on TCO. This includes a rough description of complexity of installation, configuration, update, monitoring, and troubleshooting. Explain also how easy product and landscape optimization can be done during product lifecycle (such as scalability and high availability).

In case TCO is high, explain a roadmap how simplification in next versions can be done (for example from complexity hiding to complexity reduction).

*** Testing
~Think about the test approach, especially if you enter new technology areas where the existing test tools cannot be used or where the existing test tools need to be enhanced.~

**** Integration Test with BPC
We already did PoC that technically proves BPC can directly consume data in ACDOCA through BW virtual info-provider. If we want to do further testings, we need establish a complete testing environment. The environment should synchronize with BPC code pool in a high frequency and have a complete set of data for testing.  

The current situation is RTC and BPC are in 2 different code lines. BPC is developed in KIW, and RTC is in ER9. BPC code is synchronized to ER9 in a 2-weeks frequency, which is far beyond our testing requirements. We cannot test in KIW, as KIW is not a S/4 HANA system, and transport our codes from ER9 to KIW is impossible.  

If RTC and BPC own a dedicate testing environment(I give it a name TST), that is to buy and install a new S/4 environment. Then how code from both ER9 and KIW is synchronized to TST, and then merged into the main line still needs lots of configuration and operational effort. 

There is a solution that I think is most feasible. The solution is to request BPC developers to do double maintenance in KIW and ER9. Suppose the BPC main code is already synchronized to ER9, if bug or issues are tested out, then BPC developer do fix directly in ER9, and record the changes in a special change request, which will be excluded in the final release. Meanwhile, these fixes will be re-typed in KIW. Then next time, along with the new features, these fixes will be transported to ER9 and overwrite the existing ones. 

**** Performance Test
Performance tests should be done before the initial release. We want get a general idea of how much fast RTC can achieve, and whether we can improve. The main output could be a matrix like bellow:

| Scenarios/Num-of-Items | 100,000 | 1,000,000 | 10,000,000 | 100,000,000 | 1,000,000,000 |
|------------------------+---------+-----------+------------+-------------+---------------|
| Data Validation        | 100ms   | 500ms     |            |             |               |
| Currency Translation   |         |           |            |             |               |
| Inter-unit Elimination |         |           |            |             |               |
| Reporting on-the-fly   |         |           |            |             |               |

The first column contains scenarios we think is performance relevant during consolidation; The first row is the data volume that represented by number of items of ACDOCA. Started from 100,000 lines, and ended with 1 billion lines(we can increase the end value if in real cases, there will be more line items in ACDOCA). The cells are filled with time spent in executing a scenario. Time should be differentiated by DB time, ABAP time, UI time, and the overall response time that end-user can feel. 

Besides, the corresponding memory and CPU consumption should be recorded in other tables. 

The performance result help us to understand the bottleneck, and know how to improve. Meanwhile, according to this discrete data, we could derive a performance formula which can be used to estimate the response time and do hardware sizing in a given data volume. 

*** Architecture Risks
~Explain your view on architecture-related risks and give hints about potential upcoming problems. Risks can arise for example from changes in the scope, from work-around necessary, from dependencies on other components, or from immature technologies/concepts. Fill in the table for each risk.~

**** Highly depends on BPC
| <20>                 | <50>                                               |
| Description          | RTC highly depends on BPC, and needs BPC as the main front-end tool. The situation is that BPC is not within S4HANA, and it in turns highly depends on BW cubes. BW cubes are already prohibited in S4HANA cloud releases. There is also fundamental design difference between RTC and BPC, as RTC is an embedded consolidation solution, while BPC was designed for a standalone solution. Besides, synchronizing the release strategy and time-line is quite a big challenge with 2 different teams under 2 different programs. |
| Impact(for customer) | Customer who wants S4HANA Cloud version could not fully utilize the RTC, as there is no plan for BPC running on cloud. |
| Impact Rating        | Very High                                          |
| Risk Probability     | Very High                                          |
| Mitigation Activity  | Considering even without BPC, RTC can still provide some preparation for consolidation. Differentiate consolidation into Low and High level. The low level could be done by RTC self, which already provide values to customers. The high level could be done by BPC or BCS. And some building blocks should be pluggable and replaceable, thus introduce the flexibility during implementation, which would also do help in mitigating risks. |
| Responsible Person   | PO, Arch, and Program level management team        |
| Due Date             | null                                               |

*** Planned Design Documents
~Here the sprint teams can list the software design documents (SDD), which will be created in order to implement the architecture. The list can also be created over.~

**** Validation Engine
The validation engine is built on HRF. 

**** Flexible Uploading
A uploading APP will be developed which allows to submit financial reported data to the S/4 Finance. Considering CF may have the same feature, we should combine the effort.

**** Data Exposure using BW Info-objects and Info-providers
Data is exposure for BPC consuming.

**** Data Modeling
Simply speaking, data modeling is selecting fields from foundation tables for a consolidation campaign. From a broad view, data modeling is creating artifacts includes: CDS views, HRF vocabulary, consolidation tasks, consolidation version/unit/group/scope/hierachies, master data association, data extension, and so on. All these can be viewed or executed in consolidation monitor.

**** Currency Translation
Exchange rate maintenance, assign accounts to rate methods, run translation logic in HANA.

**** ACDOCC
ACDOCC is finally decided for RTC to store consolidation result. The detail design documents can be found here. 

**** Posting Interfaces for Consolidation
A set of posting interfaces will be defined for data posting to ACDOCC. The interfaces would be called in following scenarios:
1. Automatic posting during consolidation.
2. Flexible uploading.
3. Write-back class attached on the virtual info-provider when integrated with BPC. 

The core of posting interface should be HANA enabled, so that performance targets will be achieved when do mass document postings. It core logic should be realized using AMDP including the sequential document number. 


** Glossary
Add definitions of terms which are relevant for understanding the document to the glossary. As alternative add the terms to the [[https://wiki.wdf.sap.corp/wiki/display/ArGlossary/Contribute+to+SAP%2527s+Architecture][architecture glossary in the Wiki]]. 

*** SAP existing financial consolidation applications

**** BPC

**** SEM-BCS

**** EC-CS

**** FI-LC

*** Business Rules with HANA Rules Framework

**** [[http://scn.sap.com/docs/DOC-63047][Getting started with HANA Rules Framework]]
