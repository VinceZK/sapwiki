#+STARTUP: align
#+OPTIONS: toc:1
#+PAGEID: 1774869651
#+VERSION: 85
#+TITLE: ACD of Real-time Consolidation
** Abstract
Real-time Consolidation(RTC in short) is SAP's next generation financial consolidation system, which is built on S4HANA platform and leverages HANA's in-memory technology. 

Unlike traditional standalone consolidation applications, RTC embeds consolidation logic into a centralized financial system. The centralized system we call it Central Finance(CF in short), which makes financial operation, analysis, and planning happens in a same environment, and unifies financial master data and rules across all the local subsidiaries. 

Based on the Central Finance, RTC makes real-time financial consolidation possible in the following ways:
1. Local journals are synchronized into CF in a real-time fashion, so data mapping and consolidation rules will also be applied real-timely at journal level.
2. No additional data copy and batch job is needed when running consolidation. Consolidated results can be made on-the-fly directly based on journal items. 
3. Consolidate results can be traced back to the  original transactions.
4. Local financial close, corrections, and updates can be instantly noticed.
5. Planning and simulation can be made on consolidated results, and vice versa. 

The high level consolidation building blocks (backlogs) includes:
- Data modeling based on multi-dimension database view.
- Data collection and validation.
- Inter-company reconciliation.
- Currency translation.
- Consolidation and elimination.
- Reporting.
- Collaborations.

*** Administrative Data
| Attribute        | Value                     |
|------------------+---------------------------|
| ACD              | Real-time Consolidation   |
| Related Use Case | link to Jira              |
| Responsible      | Vincent Zhang             |
| Target Readiness | Incubation                |
| Status           | in progress               |
| Version          | 0.1(Draft Version)        |
| Version History  | link to wiki History page |


** Background and Context
Financial consolidation systems are the "engine room" of the corporate finance department, enabling companies of all sizes to comply with regulatory reporting requirements, company law and global accounting standards as well satisfy management's need for periodic management reporting.

But all is not well with standalone consolidation applications that were developed since 1990's. Among them, SAP already has three: BPC, BCS, and EC-CS. Those consolidation solutions are still commonplace in some of the world's largest multinationals. According to one recent research, 47 percent of companies have made substantial investments in their financial close, filling, and reporting. Yet, despite the considerable sums of money invested in the process, management teams across the globe remain dissatisfied with the quality and timeliness of management information.

With the emergence of S4HANA and the concept of central finance, we can build an embedded financial consolidation solution based on them. As financial data is already centralized, it is not necessary to replicate it again to a standalone consolidation system. Meanwhile, RTC can also gain more from the future S4HANA Cloud platform, because of the highly distributed nature of the financial close process. It can help to standardize and harmonize the data collection, improve collaborations, and significantly reduce reporting delay between local operational systems and the corporate consolidation.

*** Number of Customers expected with release now in development 
25+ customers have explicitly stated high interest on Real-time Consolidation. For details, please refer the wikipage: [[https://wiki.wdf.sap.corp/wiki/display/ERPFINDEV/Customer+Engagement+for+Real+Time+Consolidation][Customer Engagement for Real Time Consolidation]].

*** Underlying Platform/Application Server
RTC is built on S4HANA, both On-Premise and Cloud, with On-Premise version delivering first. 

*** Comparison of BPC, BCS, and EC-CS 
**** BPC embedded version
Highly depends on BW technologies,like: virtual info-object, virtual info-provider, real-time cubes, multi info-provider, composite info-provider, aggregation level, planning functions, and so on. Compared with its standard version, the modeling is done in BW, BPC only provides a mapping UI so that the consolidation process know how to consume the BW model. 

The UI contains 2 parts: 

1. WebUI is newly developed using SAPUI5, it is mainly for customizing and administrative tasks.
2. Analytic Office with EPM add-on is for reporting.

**** BCS
BCS is too depends on BW technologies, with the difference is that it is a traditional ABAP application, that all the customizing and administrative UIs are developed using ABAP GUI. But the reporting tools is with BPC, because data is anyway exposed using BW multi-dimension views. 

From functional perspective, BCS is more appeal to large SAP clients, as it has more integration with SAP financial applications. But less attractive for those non-SAP customers or others who need more flexibility. 

**** EC-CS
It is an even older consolidation application that is the predecessor of BCS. Like BCS, it is developed totally  using ABAP, and is fully integrated with SAP financial applications. The difference is that it has nothing to do with BW. EC-CS has its own set of DB tables (ECMCT and ECMCA) to store consolidation data and related customization data.

The limits are mainly on the flexibility and performance. Reporting based on legacy Report Painter is also a drawback.

**** RTC
Regarding with RTC, as the emergence of S4HANA and ACDOCA, both flexibility and performance are well covered by core technologies. Thus its architecture would be more similar with EC-CS. But while EC-CS still has independent tables,like: /ECMCT/ for aggregated data and /ECMCA/ for line item data, RTC can direct use ACDOCA for consolidation. There is no more data copy, and it realizes the combination of OLTP and OLAP. 

As BPC already delivers fancy UI and mature consolidation logic, RTC should achieve reuse. Virtual info-providers and virtual info-objects can be used as the main modeling tool and the intermediary layer which connects BPC and S4HANA finance. Thus BPC UIs and consolidation process can run directly on the actual data.   
 
*** Product Type
Financial analytical application, with data write-back and simulation features.

*** Delivery
| Delivery Artifacts             | Comments                                               |
|--------------------------------+--------------------------------------------------------|
| ABAP & AMDP                    | Main consolidation logic                               |
| HRF/BRF+ rules                 | CDS views, HRF modeling, BRF+ objects                  |
| HANA Calculation View          | Not compliant with S4HANA Guideline, but needed by BPC |
| BW info-provider & info-object | Not compliant with S4HANA Guideline, but needed by BPC |
| CDS View                       | Reporting and Analytics models                         |
| Fiori Apps                     | UI for console, reporting, and analysis                |

*** Business Case
Consolidation is discussed in 80 % of the cases of which we have customer discussions on CF. CF carries all the financial data from the entire system landscape. It is not understood by customers why they need to load the data from somewhere else for the consolidation. Group reporting on CF has limited informative value without consolidation.CF is supplied in real-time. Necessary corrections in local close are updated real-timely. There is no need for the waiting of ETL.

Here are 2 large corporations that both have financial consolidation running on a centralized finance data repository. The requirements are always there,  

**** Sinopec
Sinopec already has a centralized finance system with all its subsidiaries financial data consolidated. AGS team implemented a solution that allow BCS consume this consolidated data directly through BW virtual info-providers and HANA calculation views. Thus reduce the ETL process, and Sinopec already gets benefits from that solution. 

**** Siemens
Siemens has established a so called global template. That means that the group defines the master data centrally, but there is ample possibility for the subsidiaries to extend the master data, for example to create additional accounts in the account hierarchy below a central given account. This is actually a quite frequent approach. Siemens does this with a naming convention: the first 6 digits are reserved for the group, digit 7 and 8 are reserved for the division, the last two digits are reserved for the subsidiary. Exception are all account numbers containing the digit 9, they are reserved for the subsidiary.

*** Main Use Cases / Functional Scope

**** Data Load

**** Data Validation

**** Currency Translation

**** Inter-Unit Elimination

**** Inter-Company Reconciliation

**** Year-End close (pre)consolidation
Traditional consolidation takes days. It needs to extract data from group's sub financial systems, which needs the sub systems finish the closing first. Then transform the data, and load it to the consolidation system. The overall closing and ETL process are very time-consuming. No bother to mention if corrections are needed, the entire process could be re-processed. Corporation stakeholders suffers waiting too long a period for consolidated statements. While Real-time Consolidation can perfectly solve the problem. RTC is based on Central Finance which acts as a central repository for all the financial data, it synchronizes journals from sub systems in a real-time fashion. RTC does consolidations directly based on the central journal repository. There is no additional data replicas needed, Consolidation experts can do pre-consolidations at anytime, without notifying sub financial system to close first.Thus he/she can find problems before year-end closing consolidation actually happens. This permits corrections can be made in sub systems before-hand. Besides, consolidation rules can even be applied in the document posting processes, which guarantee efficient and effective financial controls.

**** Acquisition & Re-organization 
When a new business entity is added/removed from the organization, management teams want see the simulated consolidated results immediately to support decision.RTC can well cope this kind of requirements. 
 
*** List all Required SAP Products/Product Versions to Support the Main Use Cases
S4HANA Finance, Central Finance 1.0, BPC //To-do: versions should be checked

*** Relevant Product Line Architecture Guideline
- [[https://wiki.wdf.sap.corp/wiki/display/SimplSuite/Architecture][S4H Architecture Guideline]]
- [[https://wiki.wdf.sap.corp/wiki/display/SuiteCDS/VDM+CDS+Development+Guideline][CDS Guideline]]
- [[https://wiki.wdf.sap.corp/wiki/display/fioritech/Development+Guideline+Portal][Fiori Overall Guideline]]
- [[https://ux.wdf.sap.corp/fiori-design/foundation/get-started/][Firoi Design Guideline]]
- [[https://wiki.wdf.sap.corp/wiki/display/ERPFINDEV/sFIN+UX+Fiori+Guidelines][sFIN UX Fiori Guideline]]
  
*** Deviations from Product Line Architecture and Product Experience Requirements
| <10>       | <l40>                                    | <l20>                |
| Rule ID    | Deviation                                | Approval Status      |
|------------+------------------------------------------+----------------------|
| OC-AR-2    | No ABAP coding or BW content shall be used for analytic data access or meta data description. BPC embedded version is highly depends on BW,  we have to develop info-objects and info-providers. | Approved by Chief Arch Klensh Christian: HANA Calc view through Virtual Provider is the right track and realistic for the integration with BPC in mid-term (half year).   But in long-term, it is expected to switch to CDS. |
| OC-APP-3   | It is not allowed to create new HANA repository objects because they do not fulfill the life-cycle requirements of Zero Downtime Management (ZDM). Existing HANA content which shall be used in S/4HANA shall be migrated / converted to ABAP managed artifacts. We must develop HANA calculation views because BPC cannot consume CDS views. Virtual info-provider can mapping to a calculation view, it is a mature technology. | Approved by Chief Arch Klensh Christian: HANA Calc view through Virtual Provider is the right track and realistic for the integration with BPC in mid-term (half year).   But in long-term, it is expected to switch to CDS. |


** Boundary Conditions
Real-time Consolidation(RTC in short) runs mainly based on Central Finance(CF in short), which can synchronize journals from all the subsidiary finance systems in a real-time fashion. CF realizes the so-called "Transactional BW"(through SLT and MDG), which breaks through the world of OLTP and OLAP. Compared to traditional ETL-based BW system, CF can significantly improve the raw data quality and reduce the delay of reporting. 
  
In other case, corporations may already have their subsidiaries using a centralized finance system (based on S4HANA finance). Thus the data synchronization is not necessary. RTC then can be run directly on S4HANA finance without the CF.
 
In both cases, RTC requires a centralized finance system that already have all the local journals consolidated in a central repository. It is under that assumption can RTC do further financial consolidation models and processes. RTC will also leverage(or reuse) SAP existing consolidation applications, like: BPC, BCS, and EC-CS. In it's initial releases, RTC will consider BPC as the main consolidation front-end.

*** Quality Attribute Scenarios
1. Data Collection
| <30>                           | <50>                                               |
| *Who initiates activity (interactor)?* | BPC consolidation front-end tools                  |
| *Addressed part of the system which executes initiated activity (executor)?* | BPC data collection console                        |
| *How does the interaction between initiator and executor take place?* | BPC data collection tool will valid if data is ready for consolidation. It will check validation rules, and allow user to do collections. |
| *Under which conditions / environment does the interaction take place?* | Mostly, during month-end or year-end closing, the group consolidation operator checks whether the data provided by lock subsidiaries is ready for consolidation. |
| *Result of activity*           | Data is correct,Performance is good                |
| *KPI*                          | n line items in xx ms                              |

*** Product Standards
Ensure compliance with product standards. To do so, go through the product standard requirements of category "architecture & technology" in the Product Standard Compliance tool (PSC) before you start defining your architecture and describe in this section how product standard requirements influence the architecture to be defined.

Add a link to the PS planning in PSC or describe deviations within this chapter.

For further information on product standards, see [[https://portal.wdf.sap.corp/wcm/ROLES://portal_content/cp/roles/cto/DevelopmentResources/Idea-To-Market/Infocenters/WS%2520Office%2520of%2520the%2520CTO/Development%2520Resources/I2M/I2M%2520Product%2520Standards][go/productstandards]]

*** Technology Decisions
Define which technologies / frameworks are used in which architecture area and for specific topics:

| Architecture                           | Technologies to be Used                              |
|----------------------------------------+------------------------------------------------------|
| Clients                                | BPC, S4HANA applications                             |
| Presentation Layer /  User Interface   | BPC WebUI(UI5), Analytic Office, Fiori, SAPGUI       |
| Business Logic Layer                   | ABAP, AMDP, CDS, Calculation View                    |
| Analytics / Reporting                  | BW info-providers, BEx Query, CDS view               |
| Integration Middle-ware                | Central Finance (based on SLT and MDG)               |
| Business Process Management / Workflow | HRF/BRF+                                             |
| Data Persistence                       | HANA Relational Database                             |
| Development Environment                | ABAP ADT, HANA Studio, BW Modeling tool,Fiori WebIDE |
| Life-cycle Management                  | ABAP CTS, Fiori CI                                   |

*** Reuse
List the reuse components (engines, objects, intrinsic/common services, 3rd party components) which have to be used for this development program/project/topic/integration scenario. Mention reuse components which explicitly must not be used within this development program.

General Principles for Reuse
- Take reuse into account in every architecture definition. Well planned reuse has a big positive influence on stability, quality, common look and feel, TCO and TCD of the complete application.
- But consider the costs in relationship to the benefits when reusing a function or feature from others. In especially check if the prerequisites (system, hardware, licenses, implementation and customizing efforts, etc) which are required to use the reuse functions are acceptable for customers. If you answer one of the following questions with yes please consult with your local reuse expert
- Does the used service or functionality force the customer to install an additional system?
- Does the usage of a service or functionality force the customer to implement and customize a new application or technology hub?
- Does the new framework or functionality which is planned exist in a similar version in other areas (Examples are rules engines, business object frameworks, master data, ...)?

The following reuse components must/should/must not be used within this development:

| <15>            | <15>            | <5>   | <5>   | <30>                           |
| Reuse Component | Owned by        | Maintenance Guaranteed? | Usage | Remark / explanation           |
|-----------------+-----------------+-------+-------+--------------------------------|
| HRF 1.6.2       | HRF team        | Yes   | must  | HANA Rule Framework must be used to build RTC's validation engine. The validation engine should permit both high performance and easy rule maintenance for LOB users. RTC use HRF to push rule validation down to HANA level.HRF license should be considered. |
| BRF+ 2.0        | BRF team        | Yes   | must  | BRF+ must be used for the reason of the compliance with S4HANA guideline. HRF cannot be used directly, and must indirectly through BRF+. Compared to HRF, BRF+ is running on ABAP level which could not permits good performance on mass data processing. RTC should combine the advantages of HRF and BRF+. |
| CDS 1.0         | CDS team        | Yes   | must  | Use CDS for modeling when ever possible. CDS is SAP's future business script targets to Cloud. Although it has function limitation and not mature enough, but we should use it as much as possible. |
| Fiori 1.0       | Fiori team      | Yes   | must  | Fiori must be used for all the UI. Fiori is the future S4HANA UI that targets to Cloud. RTC must not use any other Web UI framework, or develop its own framework. Traditional SAPGUI(including HTML GUI) is only allowed for intermediate purpose. |
| IBPF info-objects | IBPF team       | Yes   | must  | IBPF developed a lot of finance planning BW info-objects. RTC can re-used them, or do some extension whenever necessary. Beside, RTC and IBPF should combine efforts so that Consolidation and Planning can happen together. |
| Design Studio   | EPM team        | Yes   | must  | Design Studio is used to create queries. The query can be opened via various analysis tools, like: AO, Fiori Apps, and so on. It is appointed by S4HANA guideline for the only query builder, and will replace BEx in future. |
| BEx Query       | BW team         | Yes   | should | BEx query should only be used when Design Studio is not possible, or for some test purpose. |
| HANA Calculation View | HANA team       | Yes   | should | HANA Calculation view should be only used for the purpose to integrated with BPC. Other cases should use CDS instead. |
| BW              | BW team         | Yes   | should | BW cube should only be used for the purpose to integrated with BPC. RTC should avoid using BW cubes as it violate with S4HANA guideline, and it is not the future. |
| BPC 10.1        | BPC team        | Yes   | should | BPC should be used when ever possible. BPC is the only legal financial consolidation and planning system in SAP. RTC should provide the possibility to allow BPC run on CF seamlessly. In some cases if BPC cannot be used, RTC should also provide some core functionalities that can propose values for customers. |
| CF 1.0          | CF Wdf team     | Yes   | should | CF should be used when customer what its de-centralized finance systems to be somehow centralized. If a totally centralized finance system is not possible, than establishing a centralized journal repository for group reporting and analysis can be realized by CF. RTC then can use the CF to form it's data basis. |
| EC-CS           | IMS team        | Yes   | should | EC-CS is SAP's legacy ERP embedded consolidation application. EC-CS share a lot common features and ideas with RTC, like do consolidation directly on line items. RTC should research, reuse, and adopt EC-CS's functionalities whenever possible. |
| BCS             | IMS team        | Yes   | should | BCS is the legacy consolidation application based on BW that some large corporation clients are still in-use. BCS has more functionalities than BPC, but with old-style UIs and too strict, somehow, too proficient, that not all the customers like it. A lot of BCS features and functionalities could be researched, reused, and adopt to RTC. |

*** Cross-Release Compatibility
Describe boundary conditions to ensure smooth upgrade / migration.

General Principles for Cross-Release Compatibility

A new release of an SAP application can always be integrated with any release of any other SAP application that is still in mainstream and extended maintenance. After an upgrade of an SAP application, all previously used scenarios are still available.

Release Synchronization schema to be followed (Details see[[https://portal.wdf.sap.corp/wcm/ROLES://portal_content/cp/roles/cto/DevelopmentResources/ReleaseStrategyTransparency/Infocenters/WS%2520PTG/PTG/Operations%2520%2526%2520Program%2520Office/Release%2520Management][/go/releasemanagement]])

*** Other External Forces / Constraints and Assumptions
Describe other external forces, constraints and assumptions, which influence or restrict your architecture. This could also be resource, skill set and time line constraints, etc.

Real-time Consolidation highly depends on Central Finance. CF provides the data bases for the RTC to consume. The successfully implementation of CF puts directly impacts on RTC.

BPC is the only legal consolidation and planning product in SAP. RTC may be bundled with BPC for sales and marketing. If BPC


** Architecture Definition
The architecture chapter describes the main building blocks of the architecture and their relationships. Depict also how the building blocks are integrated with building blocks outside the program/topic.

~For conceptual and technical architecture diagrams use~ [[http://ency.wdf.sap.corp:1080/Modeling/Standard][Technical Architecture Modeling (TAM)]]. 

*** Architecture Context and Overview
RTC mainly interacts with 3 SAP applications: CF, BPC, and IBPF. Each takes a role as following:

1. *CF* provides a data foundation(ACDOCA) for RTC to create models on it.
2. *RTC* enable the user to do typical consolidation preparation, like: data validation, currency translation, Inter-company reconciliation, and so on.
3. *BPC* is the main consolidation tools that can be seamlessly integrated with RTC to do higher level consolidations and eliminations.
4. *IBPF* is highly integrated with RTC. Which can do planning and simulation on the consolidation results, and vice versa. 

Details on each building blocks and their relationships are explained below.

#+CAPTION: Overall Architecture Diagram
[[../image/OverallArchitectureDiagram.png]]

**** Line Item Level Data Integration
Local financial systems synchronize their line items into CF's central journal repository(ACDOCA). The synchronization is realized through SLT. It is a middle-ware which can listen changes at database level and synchronize the updates to CF real-timely. 

Data mapping happens when the newly created items are entering into CF through a master data mapping application called MDG(Master Data Governance). Mater data is mapped from local to group, these could includes: Accounts, Chart of Accounts, company code, cost center, and so on. 

There is also an error handling component(AIF) which centrally process all the processing logs. If error happens, the context is saved for future re-processing. 

This building block is developed and maintained by CF's Waldorf team. RTC is highly depends on this component which permits data quality and timeliness. Meanwhile, RTC provides validation and currency translation services to CF. Additional consolidation rules and currency translations are applied before line items saved to ACDOCA.   

**** Manual Adjustment Posting
Adjustments can be made by posting additional financial documents. These adjustment documents can be either posted in original local financial systems and then synchronized to CF, or posted directly in CF. In both cases, the consolidation validation rules should be applied and existing document posting UIs should be also reuse.

If ACDOCC is used, user has the third option to post documents to ACDOCC only for consolidation purpose. +Then a lighter document posting UI would be introduced by RTC, and less posting validation would be applied.+ This will be detial covered in the =Posting= block.  

**** Flexible Upload
Flexible upload allows user to upload reported financial data, additional financial data, and master data from a file into CF. It should be part of RTC's  =Data Collection=, but as CF also has the similar functionalities, re-usability should be considered. 

But there could be still difference between each other. I suppose CF is using flexible upload mianly for the group reporting, and the data is loaded to ACDOCA. Strict posting validation could be applied in this case; While for RTC, the financial data is uploaded only for the purpose of consolidation, and the data is saved in ACDOCC. Only light validation logic should be applied. 

Whether flexible upload is combined or how to combine still needs further investigation.   

**** Data Modeling
Data modeling is to define fields and rules for a consolidation compaign. From technique point of view, data modeling is to create multi-dimension views and consolidation rules based on foundation tables. These activities could be simplified by consolidation modeling tools. 

These foundation tables includes: ACDOCA, ACDOCC, and other data sources like ACDOCP (or customer specific data extensions). They are used to generate a fact view.

Master data views(includes Hierarchies) which are generated upon existing master data tables will then be associated to the fact view to form a multi-dimension view. The multi-dimension view can then be used for reporting and analytics. Master data could be freely extended, both horizontally and vertically, according to various consolidation requirements.

The consolidation customization data is used to define consolidation Units, Groups, and Scope. A =Unit= can be only assigned to one =Group=; =Group= can also contains sub-groups, thus to from a consolidation hierarchy. Nodes in the hierachy could be time-dependent or version-dependent. Details can be found in building block "Consolidation Unit/Group/Scope" 

Consolidation =Unit= is a kind of tree structure which defines the aspect of this consolidation campaign. For example, from the aspect of corporate organization structure, or the geography, or the products. =Scope= is a sub-tree of the total =Hierarchy= which only includes those nodes that are relevant to this consolidation campaign. Irrelevant nodes (like 10% own of the entity) are removed from the =Scope=. =Groups= are again sub-trees of =Scope= which may contain other groups or consolidation units (leaf nodes). =Groups= provides a intermediate consolidation view which is very useful for management analysis.

Fields in fact view are implicitly assigned to different roles. Roles include: Key, Consolidation dimension(unit), Account, Currency, Sub-assignment, Version, and so on. When defining CDS views, we can add an abbreviation prefix to each field's semantic name. Each field's role is then assigned without having to using an additional mapping table. Following table indicates how we category Fields to their roles:
| Field Role          | Abbr. Prefix | Semantic Name Example |
|---------------------+--------------+-----------------------|
| Key                 | K            | K.FiscalYear          |
| Account             | A            | A.AccNum              |
| Transaction         | T            | T.PostingLvl          |
| Currency            | C            | C.GroupCurr           |
| Unit                | M            | M.BaseUnit            |
| Consolidation Unit  | U            | U.RCOMP               |
| Partner Unit        | P            | P.PartnerComp         |
| Consolidation Group | G            | G.ConsGroup           |
| Account Assignment  | H            | H.SubCategory         |
| Amount              | V            | V.GroupCurrAmount     |

Those consolidation customization data are exposed via CDS views, which then can be associated with the fact view for reporting, or assigned to HRF vocabulary for rules definition. Although the consolidation hierarchy are changed frequently, but the meta of these objects are rather stable. So both the CDS views and HRF vocabulary can be pre-delivered as static artifacts (colored with yellow). 

Unlike consolidation customization view and master data view, the meta of fact view is designed for flexible customization and frequently changing. Users may add/delete new fields according to their needs. So the fact CDS view and corresponding HRF vocabulary should be generated by modeling program dynamically. For details about objects and artifacts involve in modeling process, see following diagram:  

#+CAPTION: Data Modeling Diagram
[[../image/DataModeling.png]]

This building block is dotted because it can be replaced by BPC's modeling tool. In case BPC is not possible due to release strategy or other reasons, RTC should provide a flexible modeling tool. In both cases, RTC should provide a set of modeling APIs that can generate CDS views, assign CDS views to HRF vocabulary, and allow other consolidation tools to integrate with. 

**** Data Exposure via BW/CDS
Multi-dimension views can be created either using BW info-providers or using CDS analytic views. They are both underlying modeling technologies that Data modeling tool depends on. The BW info-provider is only used to integrate with BPC and BCS. As both of them are build on BW components. 

CDS analytic views are preferred as it is SAP's future modeling scripts, and the only modeling technology allowed by S4HANA guideline. The expectation is that BW can support CDS well, so that there is no need to support 2 different modeling technologies. 

HRF vocabulary is also a data exposure technology. But it is for rule defination and exectuion. 

**** Data Collection
Data is collected from all the subsidiaries, or the de-centralized systems through various ways. In the best situation, CF already helps to collect all the data correctly and timely. Then this building block only provides validation reports to make sure the local financial data is correct and ready for the consolidation. 

But in more realistic cases, data is not that ready enough for consolidation. Some subsidiaries data may not be able to automatically synchronize into CF, or even CF is not the right approach for some instances. In that way, RTC should provide a flexible data upload mechanism which may support spreadsheets upload, manually entering, and web services APIs. Through these flexible interfaces, the raw data will be validated upon consolidation rules, and posted into ACDOCA.

The data collection process accesses foundation tables through CDS views, which are annotated with write-back classes. There are 2 reasons why not use ABAP coding:
1. CDS can make data validation pushed down to HANA.
2. CDS is easy to exposure to multiple front-end tools.

**** Inter-company Reconciliation 
Inter-company Reconciliation (ICR in short) provides you with periodic control over accounting documents that describe the accounting transactions within a corporate group. Designed to reduce the differences in corporate group consolidation, this application in Financial Accounting allows early analysis in the closing process to avoid differences altogether and to reduce the deadline pressure that normally arises during the end of a closing period.

ICR operates on the level of companies and its trading partners. To avoid currency conversion differences, the documents are reconciled in the *transaction currency*. Both individual companies and their parent companies benefit from ICR. Individual companies benefit from paired documents because they need to ensure that their own documents from accounting transactions correspond to the documents of internal trading partners. This helps avoid delays and disputes when payments are processed. Their parent companies can then make a global check on the reconciliation results for all the companies.

You can regard ICR as a special process that belongs to data collection. It is such a common usage that SAP already has this feature as a separate component called [[https://help.sap.com/saphelp_erp_fao_addon20/helpdata/en/d7/5a7c525ae17154e10000000a44176d/frameset.htm][SAP ICR]]. ICR supports the following three reconciliation processes:

1. *G/L open items reconciliation.* This process is for reconciliation of open items if most of your inter-company receivables and payables are posted to G/L accounts.
2. *G/L account reconciliation.* You use this process for reconciliation of documents that are posted to accounts which do not have open item management. This process is mostly used for reconciliation of profit and loss accounts.
3. *Customer / vendor open items reconciliation.* You use this process for reconciliation of open items. Choose this process if most of your inter-company receivables and payables are posted to customer and vendor accounts.

Currently, ICR has both dynpro UI and webdynpro UI, but without Fiori. Evaluation should be made to check if current webdynpro app can be enhanced, or new Fiori UI could be developed. The new ICR UI will access ACDOCA data through CDS exposure, and need the consolidation scope definition and reconciliation rules to be defined in the validation engine. 

**** Consolidation and Elimination 
Consolidation and elimination are two actions that usually happen together. At most time, we simply called it "consolidation". Consolidation means do aggregations on the amount that belongs to the same dimension group. Elimination means some related amounts should be eliminated to avoid unnecessary counting. Elimination usually happens between 2 trading partners, for example: Partner A sold something to partner B with amount 100 dollars. Both A and B are belong to the same business group. So, from group's point of view, the transaction amount $100 should be eliminated.

How consolidation processes depends on the rules defined in the rule engine. Customers usually define consolidation rules based on their own needs. There are also standard rules to follow, like: GAAP and IFRS, which are legal requirements that all the corporations must follow. 

There could be difference generated during consolidation. For example, when local currency amount is translated to group currency amount, due to the fluctuation of currency rate, the translated group amount could be unbalanced. Thus, adjustment documents would be posted automatically, and the difference amount will be recorded to an account that specified in the rule engine. 

The process runs in hours in traditional Consolidation applications. But within Real-time Consolidation, it should be done in minutes(without scheduling any batch jobs). Sometimes, it could be run on-the-fly without doing any document posting. For example, when the operator wants to see updated results after small adjustments or new journals come in.   

This building block could include APIs and UIs that are used to initiate, monitor, and get results from the consolidation process.  
 
**** Consolidation Scope/Group Definition

**** Reporting
Reports or queries are based on multi-dimension views that exposed either by BW or CDS. Tools like BEx Query Designer and Design Studio could be used to create queries based on multi-dimension views. Those queries can be then consumed by AO and Fiori.

Reports could be organized by consolidation hierarchies.

There are report to report navigation called [[http://help.sap.com/saphelp_scm700_ehp02/helpdata/en/4a/5b96c6517f2e24e10000000a42189b/content.htm?frameset=/en/4a/5b96c6517f2e24e10000000a42189b/frameset.htm&current_toc=/en/b2/259b06d406454fa8429240ecaed4f6/plain.htm&node_id=123&show_children=false][Report-Report Interface]](RRI in short). RRI allows you the flexibility to call a jump target (receiver) on-line from a BEx query (sender) within or outside of the BW system. Jump targets that have been assigned to a BEx query can be selected in BEx Web applications and in the BEx Analyzer. You can access them from the context menu under the Goto function.

Analytics Office also support RRI just like BEx Analyzer. Fiori Apps should develop corresponding navigation features to existing list view reports or detail transactions. The consolidation trace back requirements are actually realized through these report-to-report navigations. 

**** Validation Engine
Validation Engine is the core of financial consolidation. It is used for storing and running consolidation rules, and rules could be applied in all other building blocks. Easy customization and high performance of applying rules are the key targets that this building block should achieve.  

Validation Engine is built on existing rule frameworks HRF and BRF+. HRF stands for Hana Rule Framework. Rules maintained in HRF can be applied directly in HANA, which permits good performance. BRF+ stands for Business Rule Framework plus. BRF+ is an ABAP-based rule framework. There is a road-map that HRF and BRF+ will be merged into one. But currently HRF can be integrated into BRF+ in some degree.

How we use HRF combined with BRF+ is still under research.
 
**** Validation Rules Customization
HRF has 2 kinds of rule editors, one is Text-Based Rules, and the other is Decision Table. HRF team has made them  UI5 components, so that it can be easily integrated and reused by other applications. 

*Text-Based Rules:*
Simple, natural, and intuitive business condition language (Rule Expression Language)

#+CAPTION: Text-Based Rules
[[../image/TextRuleEditor.png]]

*Decision Table:* 
Simple and intuitive UI control that supports text rules and decision tables

#+CAPTION: Decision Table
[[../image/DecisionTable.png]]

While RTC can leverage HRF's high performance and intuitive rules editor, how to map existing rules of BPC and BCS, or even 3^{rd} party consolidation applications into HRF is still a big challenge.  
  
**** Currency Translation Engine
Currency translation is based on the HANA function: *CURRENCY_TRANSLATION*. The function use the exchange rates in table: TCURR. TCURR and other related tables forms SAP ERP's exchange rate repository. Real-time consolidation should be connected to the exchange rate repository. 

There are 3 kinds of exchange rates that consolidation needs:
1. Average rate
2. Transaction rate
3. Reporting rate

The choice of different type of rates is based on type of accounts. The currency translation engine should choose the right rate with high performance and high customization. HRF's decision table could be used in such case. 
   
**** Currency Translation Rules Customization
As describe above, HRF Decision table could be used to maintain the currency exchange rules. It should be easy to mapping exchange rate rules to decision table. 

API should also be provided to allow external rate repository to be imported into HRF. 

**** Data Foundation
Data foundations are the tables that actual source financial lines are stored. They could be mainly 3 foundation tables:
1. ACDOCA: actual financial journal items.
2. ACDOCC: aggregated journal generated during consolidation.
3. ACDOCP: aggregated journal generated during planning. 

There are 3 types of data would be stored in RTC:

*Reported financial data on line item level* | 
This is the data which central finance takes care of already: the FI line items. This is the basis of the consolidation, and normally comes from an FI system. However, we have to take care of special situations and the transformations that typically take place when the data is copied from the local accounting to the group accounting.

*Reported financial data on aggregated level* | 
There will be most likely cases where the data is not provided on line item level. Examples are very small subsidiaries, that just do not do accounting on such a detailed level (they might just use a PC program). Or I remember one case where a joint venture was managed not so jointly, so one of the two parents did not get the detailed information, but only the high level aggregated data.

Saving such kind of aggregated data to ACDOCA is not that easy, and a separate aggregated table, like ACDOCC, would be more achievable.  

*Additional data* | 
Not all data is in ACDOCA, and not all data in the full detail needed by consolidation. For example we do not have the investment information in ACDOCA. Or Financial Services store the details about the customer accounts in their own table, and only have an aggregated view in ACODCA. Another example is sub-ledgers which are not (yet) integrated into ACDOCA.

How to save this additional data? Extending fields on ACDOCA and ACDOCC, or join additional tables? Either need model to be adjusted on DB level. Ensuring the flexibility and performance at same time on the enrichment of data foundation is a big challenge(see next chapter "Data foundation enrichment").
  
*** Main Architecture Challenges and Decisions
**** TODO Have to use calculation views and BW content 
HANA and BW content is not allowed in S4HANA guideline. This is because they are not targets to Cloud. But Real-time consolidation has to use them because it has to integrate with BPC. While BPC is SAP's only legal consolidation product, it is a sub-component of BW, and fully build on BW info-providers. Ask BPC to support CDS in short term is impossible. 

| <15>            | <50>                                               |
| *Decision*      | We have to use HANA calculation View in short term. But it is expected to switch to CDS view. Hopefully, BPC will support transient provider which is generated by CDS analytic view. |
| *By*            | Chief Arch: Christian                              |
| *Date*          | <2015-11-18 Wed>                                   |
| *Description*   | balabala                                           |

**** TODO BPC should be integrated as the main consolidation front-end tool
**** TODO Consolidation and Planning should be considered together
AC120
**** Where to store the consolidated results
Helmut has described 4 options to store consolidated results:
1. Consolidation results will be saved to an ACDOCA extend ledger.
2. Consolidation results will be saved to an ACDOCA independent ledger.
3. Consolidation results will be saved to ACDOCC, a new table for consolidation.
4. Consolidation results will be saved to a BW Cube.

*ACDOCA Extend Ledger* 
The data from the subsidiaries will reside completely in one ACDOCA Ledger, all eliminations and adjustments are posted in an extend ledger. The Pros is that SFIN functionalities can be reused; While the Cons are the requirements of strictly alignment of master data, and save to ACDOCA via posting interfaces(see next section).

~Here should have some simple explanation on what is extend ledger, and what is the difference between standard ledger. Extend Ledger is now changed to the name Special Purpose Ledger, which is of the application component FI-SL. You can define ledgers for reporting purposes. You can keep these user-defined ledgers as general ledgers or subsidiary ledgers with various account assignment objects. Account assignment objects can either be SAP dimensions from various applications or customer-defined dimensions. You can refer [[http://help.sap.com/erp2005_ehp_04/helpdata/en/da/6ada3889432f48e10000000a114084/frameset.htm][SAP online help]] for more details on Special Purpose Ledger.~

*ACDOCA Independent Ledger*
The data from the subsidiaries will reside in ACDOCA. But we will use a different ledger and different master data for consolidation. We need to extend ACDOCA access so that when reading data from ACDOCA for that ledger the data from the subsidiaries in the different ledger can be added via a view (kind of a visualized ledger). This is already been in discussion to handle the challenge of integrating ledgers like Financial Services that want to stay in their own tables, but also want to eliminate the replicated or aggregated footprint in ACDOCA. This is however not available yet.

The Pros compared to ACDOCA Extend Ledger is the decoupling of master data, but the Cons is that the technology is not yet available.

*ACDOCC*
The data from subsidiaries will reside in ACDOCA. We will use a (more or less complex, but definitely flexible) view on top of ACDOCA. All data created by consolidation is stored in a new table ACDOCC.

The Pros compared the former 2 options are that fields in ACDOCC can be defined (and extended) independently from ACDOCA, and records created by consolidation functions can just be stored, no FI posting logic to be considered. The Cons are that separated data set causes it hard to find relationship between group and local data, and cannot reuse SFIN existing reports and Firoi Apps.

*BW Cube*
Similar to Planning we could store the data created by consolidation in a BW cube, while we read the subsidiary data from ACDOCA via a HANA View.

The Pros compared the former 3 options is that it is most flexible in modeling. But the Cons is that it is not the with S4HANA targets Cloud. 

| <15>            | <50>                                               |
| *Decision*      | The optimal solution would be probably to enable an extend ledger for ACDOCA for those customers which are already advanced enough to use this, and to provide ACDOCC for all others. If we can do only one, the reasonable approach in terms of customer base is probably ACDOCC. |
| *By*            | Helmut Hoffman                                     |
| *Date*          | <2015-12-11 Fri>                                   |
| *Description*   | Using an Extend Ledger on ACDOCA is the most visionary approach. But as such it contains also huge risks. Customers might not be able to harmonize the master data and transactional data in such a degree as is needed, it might even go to a decision between enabling the central finance for consolidation or for centralized operational processing. ACDOCA also contains technological challenges, in particular the question of how to do updates via the posting interface. We should avoid investing into a BW cube, this is a dead horse in light of S4HANA and B4HANA. |

**** Posting to ACDOCA via standard interfaces
When storing data in ACDOCA we should use the FI posting interface to ensure that only correct data is stored in ACDOCA. If for example data is stored in ACDOCA that violates referential integrity assumptions that are included in views, that might break HANA Views, generic programs running over the entire ACDOCA like migrations and other tools. In particular BPC is a fairly generic toolset, where the customer can define also rules that would violate these integrity assumptions. Thus going via the standard FI posting interfaces seems necessary to protect the application.

But going through the FI posting interfaces has some implications:

- Write back must be done via application ABAP coding (write back class in virtual provider or write back class in current planning enabled CDS View), not via a HANA view, not via a standard implementation for a BW infoprovider

- The posting logic might change the lines created by the consolidation engine. For example additional fields might be derived. Or tax lines might be created. We can define a reduced posting logic for consolidation mainly focusing on the referential integrity; it is not clear how far this can go. Certainly the consolidation application expects that the data is stored exactly the way it is created by the consolidation application, without any further modifications or enrichments

- Posting via ABAP and FI posting interface will have a performance impact. It also means that the consolidation can not be pushed fully to the HANA, only the calculation, but not the posting. If the data would be stored directly on a standard database table like a BW cube or ACDOCC, also the update could be done on HANA, having the entire processing in HANA.

| <15>            | <50>                                               |
| *Decision*      | Avoid automatic generated document posting to ACDOCA, using an additional Table ACDOCC instead. The ACDOCC approach can reduce the impact from the posting logic, and can improve consolidation performance by allowing both calculation and posting into HANA. |
| *By*            | Helmut Hoffman                                     |
| *Date*          | <2015-12-11 Fri>                                   |
| *Description*   | In case ACDOCC is not allowed, or customer want to use a extended ledger to save all the consolidation results. Then we might still need post through standard interfaces. The performance impact should be further investigate. For example, we can reduce the possibility that consolidation process generates adjustment documents. The adjustment documents could be posted to ACDOCA in phases before consolidation process happen. |

**** The data collection depends on Central Finance 
There are lots of experiences how data is collected from local financial systems to form a consolidation data base. 

*EC-CS and FI-LC*
EC-CS and FI-LC have the possibility to define a real-time update. Then every FI posting will also update the totals in consolidation, or even create a line item in consolidation.  There are several mappings of master data possible, for example, operation account to group account, encoding of various accounting objects into the field sub-item, and filling of custom consolidation fields via user-exits. 

The real-time update does have some enthusiastic customers using it. However, the usage is small for two reasons:

1 You have to run everything in one system.
2 The master data must be fairly aligned, the mapping capabilities are limited.

*Load from Data Stream in SEM-BCS*
SEM-BCS allowed the customer to use a BW extractor, define the mappings in some customizing and then load the data into BCS at periodic intervals. This was not used very often. It is too difficult to define the rules and to understand, where the data is coming from

*Delta Load in SEM-BCS*
BCS also offers the possibility to load the data from FI via an extractor into an operational ODS and then to transfer it from there into BCS. Delta load is supported, so a continuous data transfer is possible.

A direct load into BCS instead of the intermediate step with the operational ODS was rejected by the customers with the reason that they need the intermediate ODS in order to understand how the data in BCS and the operational data relate to each other, the intermediate result in the ODS makes the transformation traceable.

| <15>            | <50>                                               |
| *Decision*      | Central Finance makes sense to unify the master data when data collection is made real-time. But it will make tracing back to original transaction difficult. It is also not realistic to force all the company codes into a same corporate master data. There should be auxiliary data collection methods and master data extension solutions provided by RTC. |
| *By*            | Helmut Hoffman                                     |
| *Date*          | <2015-12-11 Fri>                                   |
| *Description*   | The data in the group close and in the local close typically do use quite different master data. To some extent companies are trying to avoid this, by using central master data, but resistance is large. The need for specialized master data can be channeled by using defined extension mechanisms, but there are also cases where unification just is not possible, for example if the regulatory bodies define certain master data. With the central finance approach, it does make sense to unify the master data when replicating into the central finance system. Theoretically, you could just do a 1:1 replication, each company code replicating into its central finance with its own master data, but that would defeat some of the purposes of a central finance system like an early overview over the data. However, it is not realistic to force all company codes into the same corporate master data in central finance, as this on the one hand would make it difficult to trace back the data to the original posting. At the same time it would make it difficult to move operational processes like payment to the central hub, as the local extensions / changes to the master data are likely to affect these operational processes. The central finance approach makes it clearly more probable to have data in ACDOCA which can be used right away for consolidation, but considering the situation today, where massive data mapping, data recoding and data enrichment is done for consolidation, it seems unlikely that this will be the case for all, or even the majority of the customers. |

**** TODO Master data extension
**** TODO Data foundation enrichment
**** TODO Rule framework
Describe why HRF/BRF+ is chosen as the reuse rule framework. 

**** TODO CDS, AMDP and HRF as the main push-down-to-HANA methods
**** TODO Fiori as the main UI technology
*** TODO Integration with other Systems
**** Integration with BPC
**** Integration with CF
**** Integration with IBPF
**** Public APIs and Contracts
The following table lists all public APIs which are offered, be it newly created API or changes on existing APIs
| <20>                 | <15>            | <10>       | <45>                                          |
| Name of API          | Type            | Changed/New | Description                                   |
|----------------------+-----------------+------------+-----------------------------------------------|
| Consolidation Fact Table View | BW info-provider | New        | Provide a BW composite provider to let BPC consume real-time data in ACDOCA |
| Consolidation Master Data View | BW info-object  | Changed    | Consolidation master data is provided to BPC through virtual info-objects. Virtual info-objects is based on HANA views, and can access ERP master data directly. It is expected that Planning and Consolidation should share a same set of virtual info-objects. The existing info-objects developed by IBPF could be extended to fulfill both requirements. |

*** TODO Security 
Describe how the architecture protects the software against attacks or misuse.

To do so, define how communication channels (protocol, data, ...) are protected. Describe how authentication, authorization and logging are performed. Consider architecture requirements pertaining to confidentiality, integrity and availability. 

*** TODO Deployment and Operations
It is recommended to work with the local Technical Component and Delivery Architecture (TCDA) team on defining deployment and operations architecture. Contact is the "Delivery Architecture Engineer" maintained in [[https://ifp.wdf.sap.corp/sap(bD1lbiZjPTAwMSZpPTEmcz1TSUQlM2FBTk9OJTNhcHdkZjU3ODJfSUZQXzAxJTNhWEhRWUJUMFlnaXNneEZlWWZTemIwR1FhWnZxaXotY2lkX1Z3TUF0Zy1BVFQ=)/bc/bsp/sap/zpr/default.htm][program repository]] entry of your program.

**** Deployed Component Structure and Deployment Options
Show all interdependencies of (groups of) software components using a package diagram (TAM). Assign the components to software layers, for example see: https://wiki.wdf.sap.corp/display/archGov/Software+Layers

Describe software component structure, package structure and their deployment options. Deployment options describe the different possibilities how the software components can be distributed across different systems. Indicate cross-component communication. Mention explicitly, if there are new dependencies between software components.

Describe deployment unit and process component structure if relevant.

**** System Landscape
Describe typical system landscape required to run the software developed within this program productive at a customer site. Show how the main deployable building blocks are distributed within that landscape. Determine which landscape components are mandatory and which are optional to run the software

**** Operation Concept
Describe how the planned software is operated and estimate the impact on TCO. This includes a rough description of complexity of installation, configuration, update, monitoring, and troubleshooting. Explain also how easy product and landscape optimization can be done during product lifecycle (such as scalability and high availability).

In case TCO is high, explain a roadmap how simplification in next versions can be done (for example from complexity hiding to complexity reduction).

*** TODO Testing
Think about the test approach, especially if you enter new technology areas where the existing test tools cannot be used or where the existing test tools need to be enhanced.

*** Architecture Risks
Explain your view on architecture-related risks and give hints about potential upcoming problems. Risks can arise for example from changes in the scope, from work-around necessary, from dependencies on other components, or from immature technologies/concepts. Fill in the table for each risk.

**** Highly depends on BPC
| <20>                 | <50>                                               |
| Description          | RTC highly depends on BPC, and needs BPC as the main front-end tool. The situation is that BPC is not within S4HANA, and it in turns highly depends on BW cubes. BW cubes are already prohibited in S4HANA cloud releases. There is also fundamental design difference between RTC and BPC, as RTC is an embedded consolidation solution, while BPC was designed for a standalone solution. Besides, synchronizing the release strategy and time-line is quite a big challenge with 2 different teams under 2 different programs. |
| Impact(for customer) | Customer who wants S4HANA Cloud version could not fully utilize the RTC, as there is no plan for BPC running on cloud. |
| Impact Rating        | Very High                                          |
| Risk Probability     | Very High                                          |
| Mitigation Activity  | Considering even without BPC, RTC can still provide some preparation for consolidation. Differentiate consolidation into Low and High level. The low level could be done by RTC self, which already provide values to customers. The high level could be done by BPC or BCS. And some building blocks should be pluggable and replaceable, thus introduce the flexibility during implementation, which would also do help in mitigating risks. |
| Responsible Person   | PO, Arch, and Program level management team        |
| Due Date             | null                                               |

*** Validation Engine and Currency Translation Architecture Details
Consolidation rules validation and currency translation could be both built on HRF. 

*** Design of ACDOCC
*** Planned Design Documents
Here the sprint teams can list the software design documents (SDD), which will be created in order to implement the architecture. The list can also be created over 

**** TODO Validation Engine 
The validation engine is built on HRF. 

**** TODO Flexible Uploading
Some company codes can using a upload UI to submit it's consolidated financial data.

**** TODO Data Modeling using BW info-objects and info-providers. 
The data model is for BPC's consume.

**** TODO Currency Translation Engine
Exchange rate maintenance, assign accounts to rate methods, run translation in HANA.

**** TODO Consolidation documents posting interfaces 
The auto-generated documents during consolidation should be posted to either ACDOCA or ACDOCC.


** Glossary
Add definitions of terms which are relevant for understanding the document to the glossary. As alternative add the terms to the [[https://wiki.wdf.sap.corp/wiki/display/ArGlossary/Contribute+to+SAP%2527s+Architecture][architecture glossary in the Wiki]]. 

*** SAP existing financial consolidation applications

**** BCS

*** Business Rules with HANA Rules Framework

**** [[http://scn.sap.com/docs/DOC-63047][Getting started with HANA Rules Framework]]
